# Amaidesu 配置文件模板
#
# 配置层次说明
# ================================
# 此配置文件是用户主配置，包含：
# 1. 全局配置（LLM、MaiCore连接等）
# 2. Provider启用列表和配置
# 3. Pipeline配置
#
# 配置说明：
# - Provider 和 Pipeline 的配置统一在本文件中管理
# - 配置路径：[providers.input.xxx], [providers.output.xxx], [pipelines.xxx]
#
# 配置路径结构（简洁且语义清晰）：
# - [providers.input.{provider_name}] - Input Provider 配置
# - [providers.output.{provider_name}] - Output Provider 配置
# - [providers.decision.{provider_name}] - Decision Provider 配置

[meta]
version = "0.2.0"  # 配置模板版本，用于自动更新检测

# ========== 全局LLM配置 ==========

# 标准 LLM 配置（用于高质量任务）
[llm]
client = "openai"              # openai（所有提供 OpenAI 兼容 API 的服务，如 Ollama、LM Studio、vLLM 等）
model = "gpt-4"
temperature = 0.2
api_key = "your-api-key"                    # 可选，如果不设置将使用环境变量
base_url = "https://api.openai.com/v1"      # 可选，用于自定义API端点
max_tokens = 1024
max_retries = 3                 # 可选，默认 3
retry_delay = 1.0               # 可选，默认 1.0

# 快速 LLM 配置（用于低延迟任务，如 Avatar 表情分析）
[llm_fast]
client = "openai"
model = "gpt-3.5-turbo"
temperature = 0.2
api_key = "your-api-key"
base_url = "https://api.openai.com/v1"
max_tokens = 1024

# 视觉语言模型配置（用于图像理解任务）
[vlm]
client = "openai"
model = "gpt-4-vision-preview"
temperature = 0.3
api_key = "your-api-key"
base_url = "https://api.openai.com/v1"
max_tokens = 1024

# 本地 Ollama 配置（可选）
# 注意：Ollama、LM Studio、vLLM 等都提供 OpenAI 兼容 API，使用 client = "openai" 并配置 base_url 即可
[llm_local]
client = "openai"
model = "llama3"
base_url = "http://localhost:11434/v1"  # Ollama 默认地址
api_key = "sk-dummy"  # Ollama 不需要真实 API key

# ========== 共享服务配置 ==========

# DG-Lab 硬件控制服务
[dg_lab]
# DG-Lab API 地址
api_base_url = "http://127.0.0.1:8081"
# 默认强度 (0-200)
default_strength = 10
# 默认波形预设: small | medium | big | random
default_waveform = "big"
# 默认电击持续时间（秒）
shock_duration_seconds = 2.0
# HTTP 请求超时时间（秒）
request_timeout = 5.0
# 最大强度限制（安全保护）
max_strength = 50
# 是否启用安全限制（推荐启用）
enable_safety_limit = true

# ========== Amaidesu核心配置 ==========

[general]
# Amaidesu 在 MaiCore 中注册的平台标识符
platform_id = "amaidesu"

# ========== VTuber 人设配置 ==========
# 此配置段用于定义 VTuber 的性格和说话风格
# 被 LocalLLMDecisionProvider 等使用 LLM 的 Provider 引用
[persona]
# VTuber 名字
bot_name = "麦麦"

# 性格描述（50字以内）
personality = "活泼开朗，有些调皮，喜欢和观众互动"

# 说话风格约束（指导 LLM 生成回复的风格）
style_constraints = "口语化，使用网络流行语，避免机械式回复，适当使用emoji"

# 用户称呼
user_name = "大家"

# 回复长度限制（字数）
max_response_length = 50

# 情感表达强度 (1-10, 1=平淡, 10=丰富)
emotion_intensity = 7

[maicore]
# MaiCore WebSocket 服务器地址
host = "127.0.0.1"
# MaiCore WebSocket 服务器端口
port = 8000
# token = "your_maicore_token_if_needed" # 如果 MaiCore 需要认证，取消注释并设置

# 讯飞 RTASR 实时识别凭据（可选）
[spark_rtasr]
app_id = ""
access_key_id = ""
access_key_secret = ""
# 可选：自定义 websocket URL（默认官方地址）
# ws_url = "wss://office-api-ast-dx.iflyaisol.com/ast/communicate/v1"

# HTTP回调服务器配置
[http_server]
enable = true
host = "127.0.0.1"
port = 8080
callback_path = "/maicore_callback"

# ========== 上下文管理器配置 ==========

[context]
# 上下文管理器配置
storage_type = "memory"  # 存储类型: memory 或 file
max_messages_per_session = 50  # 每个会话保留的最大消息数
max_sessions = 100  # 最大会话数
session_timeout_seconds = 3600  # 会话超时时间（秒）
enable_persistence = false  # 启用持久化（暂未实现）

# ========== 日志配置 ==========

[logging]
# 是否启用文件日志
enabled = true
# 日志格式: jsonl (JSON Lines) 或 text (纯文本)
format = "jsonl"
# 日志文件目录 (相对于项目根目录)
directory = "logs"
# 最小日志级别: TRACE | DEBUG | INFO | WARNING | ERROR | CRITICAL
level = "INFO"
# 文件轮转触发条件: "10 MB", "1 day", "00:00", "weekly", "monthly"
rotation = "10 MB"
# 日志保留时间: "7 days", "1 week", "1 month", "1 year"
retention = "7 days"
# 压缩格式: "zip", "gz", "tar", "" (禁用)
compression = "zip"
# 是否按会话分割日志文件（默认：false）
# 启用后，每次启动生成新文件（文件名包含时分秒，如 amaidesu_20260207_150423.jsonl）
# 禁用时，同一天多次启动会追加到同一文件（如 amaidesu_2026-02-07.jsonl）
split_by_session = false

# ============================================================
# Pipeline 配置
# ============================================================

# 限流管道 - 限制消息发送频率
[pipelines.rate_limit]
priority = 100
enabled = true
global_rate_limit = 100  # 全局每分钟最大消息数
user_rate_limit = 10     # 每用户每分钟最大消息数
window_size = 60         # 滑动窗口大小（秒）

# 相似文本过滤管道 - 过滤重复消息
[pipelines.similar_filter]
priority = 500
enabled = true
similarity_threshold = 0.85  # 相似度阈值 (0.0-1.0)
time_window = 5.0            # 检查窗口时间范围（秒）
min_text_length = 3          # 最小处理文本长度
cross_user_filter = true     # 是否跨用户过滤相似消息

# === 输出管道（OutputPipeline）===
# OutputPipeline 示例：敏感词过滤
[pipelines.profanity_filter]
# OutputPipeline 配置
[pipelines.profanity_filter.output]
enabled = true
priority = 100
# 敏感词列表
words = ["测试脏话", "示例敏感词"]
replacement = "***"
# 可选：从文件加载
# wordlist_file = "data/profanity_words.txt"
# 是否过滤 TTS 文本（默认：true）
filter_tts = true
# 是否过滤字幕文本（默认：true）
filter_subtitle = true
# 是否区分大小写（默认：false）
case_sensitive = false
# 匹配到敏感词是否丢弃整个消息（默认：false）
drop_on_match = false

# ========== Provider配置 ==========

# === 输入Provider（Input Domain） ===
[providers.input]
enabled = true
# 启用的输入Provider列表
enabled_inputs = [
    # 控制台输入（开发测试用）
    # "console_input",

    # B站弹幕输入
    # "bili_danmaku",           # 普通B站弹幕
    # "bili_danmaku_official",  # B站官方弹幕（不要和bili_danmaku同时启用）
    # "bili_danmaku_official_maicraft",  # B站官方弹幕（MaiCraft专用）

    # 语音输入
    # "stt",                     # 语音转文字（讯飞ASR + Silero VAD）

    # 其他输入
    # "mock_danmaku",           # 模拟弹幕
    # "read_pingmu",            # 读屏木
    # "mainosaba",              # Mainosaba读屏
]

# === 输出Provider（Output Domain） ===
[providers.output]
enabled = true
concurrent_rendering = true          # 是否并发渲染到多个Provider
error_handling = "continue"          # 错误处理策略: continue（继续） | stop（停止）
render_timeout = 10.0                # 单个Provider渲染超时（秒），0表示不限制

# 启用的输出Provider列表
enabled_outputs = [
    # 基础输出（推荐启用）
    "subtitle",     # 字幕
    "vts",          # VTS控制

    # TTS输出（选择一个或多个）
    # "tts",         # Edge TTS
    # "omni_tts",    # Omni TTS (GPT-SoVITS)

    # 虚拟形象输出
    # "avatar",      # 虚拟形象输出（支持VTS/VRChat/Live2D）

    # OBS控制
    # "obs_control", # OBS控制（文本显示、场景切换）

    # 其他输出
    # "sticker",     # 表情贴纸
    # "remote_stream",  # 远程流媒体输出
    # "warudo",      # Warudo控制
]

# ExpressionGenerator配置
[providers.output.expression_generator]
default_tts_enabled = true
default_subtitle_enabled = true
default_expressions_enabled = true
default_hotkeys_enabled = true

# === 决策Provider（Decision Domain） ===
[providers.decision]
enabled = true
# 当前使用的决策Provider
active_provider = "maicore"
# 支持的决策Provider列表（用于运行时切换验证）
available_providers = [
    "maicore",  # MaiCore决策（默认，通过WebSocket连接MaiCore）
    "llm",      # LLM（直接调用LLM生成回复）
    "maicraft", # MaiCraft弹幕游戏决策
]

# ========== Provider配置示例 ==========
# 以下为各 Provider 的配置示例，取消注释并填写相应参数即可启用

# --- BiliDanmakuOfficialInputProvider ---
# [providers.input.bili_danmaku_official]
# id_code = "your_id_code"
# app_id = "your_app_id"
# access_key = "your_access_key"
# access_key_secret = "your_access_key_secret"

# --- STT InputProvider (语音转文字) ---
[providers.input.stt]
# 讯飞 ASR 配置（必填）
[providers.input.stt.iflytek_asr]
appid = "your_appid"
api_key = "your_api_key"
api_secret = "your_api_secret"
host = "iat-api.xfyun.cn"  # 语音听写流式版 API 地址
path = "/v2/iat"            # 语音听写流式版 API 路径

# VAD 配置（可选）
[providers.input.stt.vad]
enable = true
vad_threshold = 0.5
silence_seconds = 1.0

# 音频配置（可选）
[providers.input.stt.audio]
sample_rate = 16000
channels = 1
stt_input_device_name = ""  # 指定麦克风设备，留空使用默认

# 消息配置（可选）
[providers.input.stt.message_config]
user_id = "stt_user"
user_nickname = "语音"

# --- MaiCore DecisionProvider ---
# [providers.decision.maicore]
# host = "127.0.0.1"
# port = 8000
# connect_timeout = 10.0
# reconnect_interval = 5.0

# --- LLM DecisionProvider ---
# [providers.decision.llm]
# fallback_mode = "simple"  # simple | echo | error

# --- Subtitle OutputProvider ---
# [providers.output.subtitle]
# font_size = 32
# window_width = 1000
# window_height = 720

# --- VTS OutputProvider ---
# [providers.output.vts]
# vts_host = "127.0.0.1"
# vts_port = 8000

# --- TTS OutputProvider ---
# [providers.output.tts]
# voice = "zh-CN-YunxiNeural"
# rate = "+0%"
# volume = "+0%"

# ========== 事件总线配置 ==========

[event_bus]
# 是否启用事件数据验证（建议仅 debug 模式开启）
# 开启后会验证所有已注册事件的数据格式
enable_validation = false
