# Amaidesu 配置文件

# === 全局 LLM 配置 ===
# 重要：这是项目通用的 LLM 配置，供所有模块和插件使用
# Avatar 自动表情、插件等功能都会使用这些配置
[llm]
# 标准 LLM 配置（用于高质量任务）
model = "Pro/deepseek-ai/DeepSeek-V3.2"
temperature = 0.2
api_key = "your-api-key"                    # 可选，如果不设置将使用环境变量
base_url = "https://api.siliconflow.cn/v1/" # 可选，用于自定义API端点
max_tokens = 1024

[llm_fast]
# 快速 LLM 配置（用于低延迟任务，如 Avatar 表情分析）
model = "Qwen/Qwen3-8B"
temperature = 0.2
api_key = "your-api-key"                    # 可选，如果不设置将使用环境变量
base_url = "https://api.siliconflow.cn/v1/" # 可选，用于自定义API端点
max_tokens = 1024

[vlm]
# 视觉语言模型配置（用于图像理解任务）
model = "zai-org/GLM-4.6V"
temperature = 0.3
api_key = "your-api-key"
base_url = "https://api.siliconflow.cn/v1/"
max_tokens = 1024

# === Amaidesu 核心配置 ===
[general]
# Amaidesu 在 MaiCore 中注册的平台标识符
platform_id = "amaidesu_default"

[maicore]
# MaiCore WebSocket 服务器地址
host = "127.0.0.1"
# MaiCore WebSocket 服务器端口
port = 8000
# token = "your_maicore_token_if_needed" # 如果 MaiCore 需要认证，取消注释并设置

[spark_rtasr]
# 讯飞 RTASR 实时识别凭据
# app_id = ""
# access_key_id = ""
# access_key_secret = ""
# 可选：自定义 websocket URL（默认官方地址）
# ws_url = "wss://office-api-ast-dx.iflyaisol.com/ast/communicate/v1"
app_id = ""
access_key_id = ""
access_key_secret = ""


[http_server]
# 是否启用本地 HTTP 回调服务器
enable = true
# 监听的主机地址
host = "127.0.0.1"
# 监听的端口
port = 8080
# MaiCore 或其他服务访问的回调路径
callback_path = "/maicore_callback"

# 上下文管理器配置
[context_manager]
enabled = true

# 上下文格式化配置
[context_manager.formatting]
separator = "\n"           # 上下文项之间的分隔符
add_provider_title = false # 是否在上下文前添加提供者名称
title_separator = ": "     # 如果添加提供者名称，使用的分隔符

# 上下文长度限制配置
[context_manager.limits]
default_max_length = 1000 # 默认上下文最大长度
default_priority = 100    # 默认优先级值

# 通用虚拟形象控制系统配置
[avatar]
# 全局启用虚拟形象控制系统
enabled = true

# 默认活跃适配器（如果没有设置，将使用第一个注册的适配器）
# 可选值: "vts", "vrc", "live2d" 等
default_adapter = "vts"

# 自动表情配置
[avatar.auto_expression]
# 是否启用自动表情功能
# 启用后，收到消息时会自动分析文本并设置表情
enabled = false
# 最小文本长度（少于这个长度的文本不会触发）
min_text_length = 2

# ========== 新增：智能触发配置 ==========

# 简单回复过滤（优先级最高，快速本地判断）
# 过滤"好的"、"嗯"等简单确认语
simple_reply_filter_enabled = true
simple_reply_patterns = [
    "^[好的好的]$", "^[好呀]$", "^[好的]$",
    "^[嗯嗯]$", "^[嗯]$", "^[收到]$",
    "^[知道了]$", "^[明白]$", "^[OK]$", "^[ok]$",
    "^(好|行|可以)[呀啊嘛。！!]*$"
]

# 时间间隔控制（快速本地判断）
# 避免频繁调整表情
time_interval_enabled = true
min_time_interval = 5.0  # 秒

# LLM智能判断（重要性 + 情感分析 + 变化检测）
# 注意：通过前两层过滤后才执行，使用小模型成本低
# 一次调用完成3个任务：判断内容重要性、分析情感、检测情感变化
llm_judge_enabled = true

# 情感历史记录（用于情感变化检测）
max_emotion_history = 5

# 调试配置
debug_mode = false
log_filtered_messages = true

# LLM 配置（用于自动文本分析和表情选择）
[avatar.llm]
# 启用 LLM 功能
enabled = true

# LLM 类型：使用全局配置的哪个 LLM
# "llm" - 标准LLM（更准确但较慢）
# "llm_fast" - 快速LLM（推荐，平衡速度和质量）
# "vlm" - 视觉语言模型
type = "llm_fast"

# 自定义 LLM 配置（可选，如果不设置则使用全局配置）
# 如果需要覆盖全局配置，取消下面的注释并填写
# model = "deepseek-chat"
# api_key = "your-api-key"
# base_url = "https://api.siliconflow.cn/v1"
# temperature = 0.1
# max_tokens = 100

# 语义动作自定义映射
[avatar.semantic_actions.happy_expression]
description = "开心的表情"

# VTS 平台特定覆盖
[avatar.semantic_actions.happy_expression.platforms.vts]
MouthSmile = 1.0
EyeOpenLeft = 0.9
EyeOpenRight = 0.9

# VRChat 平台特定覆盖（OSC 地址）
[avatar.semantic_actions.happy_expression.platforms.vrc]
"/input/face/eyes" = 1.0
"/input/face/mouth_smile" = 1.0

[avatar.semantic_actions.sad_expression]
description = "悲伤的表情"

[avatar.semantic_actions.sad_expression.platforms.vts]
MouthSmile = -0.5
EyeOpenLeft = 0.5
EyeOpenRight = 0.5
MouthOpen = 0.2

[avatar.semantic_actions.surprised_expression]
description = "惊讶的表情"

[avatar.semantic_actions.surprised_expression.platforms.vts]
MouthOpen = 0.8
EyeOpenLeft = 1.0
EyeOpenRight = 1.0

[avatar.semantic_actions.angry_expression]
description = "生气的表情"

[avatar.semantic_actions.angry_expression.platforms.vts]
MouthSmile = -0.8
EyeOpenLeft = 0.6
EyeOpenRight = 0.6

[avatar.semantic_actions.close_eyes]
description = "闭眼"

[avatar.semantic_actions.close_eyes.platforms.vts]
EyeOpenLeft = 0.0
EyeOpenRight = 0.0

[avatar.semantic_actions.open_eyes]
description = "睁眼"

[avatar.semantic_actions.open_eyes.platforms.vts]
EyeOpenLeft = 1.0
EyeOpenRight = 1.0

[avatar.semantic_actions.neutral]
description = "中性表情"

[avatar.semantic_actions.neutral.platforms.vts]
MouthSmile = 0.0
MouthOpen = 0.0
EyeOpenLeft = 1.0
EyeOpenRight = 1.0

# 管道配置
[pipelines]
# 示例：启用并配置 throttle 管道
# [pipelines.throttle]
# priority = 100        # 数字越小优先级越高，此行存在即表示启用
# global_rate_limit = 1 # 可选：覆盖 throttle/config.toml 中的 global_rate_limit
# user_rate_limit = 5    # 可选：覆盖 throttle/config.toml 中的 user_rate_limit

# 示例：启用 message_logger 管道，使用其默认配置
# [pipelines.message_logger]
# priority = 200

# 示例：启用 similar_message_filter 管道，并覆盖其时间窗口
# [pipelines.similar_message_filter]
# priority = 300
# time_window = 10.0 # 覆盖 similar_message_filter/config.toml 中的 time_window

# 示例：启用并配置 command_processor 管道 (入站)
[pipelines.command_processor]
# 这是一个入站管道，用于处理和执行来自 MaiCore 消息中的命令
# 例如，执行 VTubeStudio 热键，然后从文本中移除命令标记
priority = 50
# direction = "inbound" # 此管道的 direction 已在其自己的 config 中设置，此处无需重复
# 可以在此覆盖 command_map
# command_map = { vts_trigger_hotkey = { service = "vts_control", method = "trigger_hotkey" } }

# 插件全局配置
[plugins]
# === 新格式：启用列表 ===
# 取消注释来启用插件，注释掉来禁用
enabled = [
    # 基础功能（建议启用）
    "console_input",
    "keyword_action",
    "llm_text_processor", # LLM文本处理器

    # 游戏互动
    # "mainosaba",        # 魔裁游戏
    # "arknights",        # 明日方舟
    # "minecraft",        # 我的世界

    # 输入功能（语音和文本输入）
    # "stt",              # 语音识别
    # "funasr_stt",       # FunASR语音识别
    # "bili_danmaku",     # B站弹幕输入
    # "bili_danmaku_official",       # B站官方弹幕（不要和bili_danmaku同时启用）
    # "bili_danmaku_official_maicraft",  # B站弹幕-MaiCraft版（不要和bili_danmaku_selenium同时启用）
    # "bili_danmaku_selenium",        # B站弹幕-Selenium版
    # "mock_danmaku",     # 模拟弹幕输入
    # "read_pingmu",      # 读屏木输入
    # "message_replayer", # 消息重放器

    # 输出功能（语音和视觉输出）
    # "tts",              # 语音合成
    # "gptsovits_tts",    # GPT-SoVITS TTS
    # "omni_tts",         # Omni TTS
    # "subtitle",         # 字幕生成
    # "sticker",          # 贴纸生成
    # "emotion_judge",    # 情感判断

    # 外部控制和集成
    # "vtube_studio",     # VTubeStudio控制
    # "warudo",           # Warudo控制
    # "obs_control",      # OBS Studio控制
    # "dg_lab_service",   # DG-Lab服务
    # "dg-lab-do",        # DG-Lab DO
    # "vrchat", # VRChat控制

    # 监控和流媒体
    # "screen_monitor",   # 屏幕监控
    # "remote_stream",    # 远程串流

    # 游戏相关
    # "maicraft",         # MaiCraft游戏

    # 系统工具
    # "command_processor",  # 命令处理器（通常作为管道使用）
]

# === 旧格式（向后兼容，可选） ===
# 以下配置仍然有效，但会被enabled列表覆盖
# enable_console_input = true
# enable_stt = false
# ...（保留原有配置作为注释示例）

# ========== 新增：Phase 4 渲染层配置 ==========

# 输出层配置（Phase 4新增）
[rendering]
# 是否启用输出层
enabled = true
# 是否并发渲染到所有Provider
concurrent_rendering = true
# 错误处理策略：continue（继续）、stop（停止）、drop（丢弃）
error_handling = "continue"

# 启用的输出Provider列表
outputs = [
    # 基础输出（推荐启用）
    "subtitle",     # 字幕
    "vts",          # VTS控制

    # TTS输出（选择一个或多个）
    # "tts",         # Edge TTS
    # "omni_tts",    # Omni TTS (GPT-SoVITS)

    # 其他输出
    # "sticker",     # 表情贴纸
]

# ExpressionGenerator配置
[rendering.expression_generator]
# 默认TTS是否启用
default_tts_enabled = true
# 默认字幕是否启用
default_subtitle_enabled = true
# 默认表情是否启用
default_expressions_enabled = true
# 默认热键是否启用
default_hotkeys_enabled = true

# ========== 各个Provider的详细配置 ==========

# TTS Provider配置
[rendering.outputs.tts]
type = "tts"
# TTS引擎：edge 或 omni
engine = "edge"
# Edge TTS语音
voice = "zh-CN-XiaoxiaoNeural"
# 音频输出设备名称（留空使用默认设备）
output_device_name = ""

# Omni TTS配置（仅在engine=omni时生效）
[rendering.outputs.tts.omni]
# Omni TTS API地址
api_url = "http://localhost:9880"
# 模型名称
model = "path/to/model"
# 说话人ID
speaker = 0
# 语速
speed = 1.0
# 音调
pitch = 1.0
# 音量
volume = 1.0

# Subtitle Provider配置
[rendering.outputs.subtitle]
type = "subtitle"
# 字幕窗口宽度
window_width = 800
# 字幕窗口高度
window_height = 100
# 字体大小
font_size = 24
# 字体颜色
font_color = "#FFFFFF"
# 背景颜色
bg_color = "#000000"
# 背景透明度（0-255）
bg_alpha = 180
# 字幕显示位置（top/center/bottom）
position = "bottom"
# 自动隐藏延迟（秒，0表示不隐藏）
auto_hide_delay = 5.0
# 是否启用拖拽
draggable = true
# 是否启用Chroma-key（OBS抠图）
chroma_key_enabled = false
# Chroma-key颜色
chroma_key_color = "#00FF00"

# Sticker Provider配置
[rendering.outputs.sticker]
type = "sticker"
# 贴纸大小（相对于窗口宽度的比例，0-1）
sticker_size = 0.33
# 贴纸旋转角度（度）
sticker_rotation = 0
# 贴纸显示时长（秒）
display_duration = 3.0
# 贴纸冷却时间（秒，防止刷屏）
cooldown = 5.0
# 贴纸目录
sticker_dir = "data/stickers"
# 默认贴纸（当没有关键词匹配时使用）
default_sticker = "default.png"

# VTS Provider配置
[rendering.outputs.vts]
type = "vts"
# VTS WebSocket地址
vts_host = "localhost"
vts_port = 8001
# 是否自动连接
auto_connect = true
# 连接超时（秒）
connect_timeout = 10.0
# 重连间隔（秒）
reconnect_interval = 5.0
# 是否启用LLM智能热键匹配
llm_matching_enabled = false
# LLM配置（可选，不设置则使用全局llm配置）
# llm_type = "llm_fast"  # llm, llm_fast, vlm
# max_hotkey_candidates = 5

# Omni TTS Provider配置
[rendering.outputs.omni_tts]
type = "omni_tts"
# Omni TTS API地址
api_url = "http://localhost:9880"
# 模型路径
model_path = "path/to/model"
# 说话人ID
speaker_id = 0
# 语速
speed = 1.0
# 音调
pitch = 1.0
# 音量
volume = 1.0
# 音频输出设备名称（留空使用默认设备）
output_device_name = ""
# 是否启用流式TTS
stream_enabled = true
# 缓存目录
cache_dir = "data/omni_tts_cache"
# 最大缓存数量（0表示不限制）
max_cache_size = 100
