# Amaidesu é…ç½®æ–‡ä»¶
#
# ğŸ“ é…ç½®æ ¼å¼è¯´æ˜ï¼ˆ5å±‚æ¶æ„ï¼‰
# ================================
# å½“å‰ä½¿ç”¨ç»Ÿä¸€çš„ [providers.*] é…ç½®æ ¼å¼ç®¡ç†æ‰€æœ‰Providerï¼š
#   - [providers.input]    è¾“å…¥Providerï¼ˆLayer 1: Inputï¼‰
#   - [providers.decision] å†³ç­–Providerï¼ˆLayer 3: Decisionï¼‰
#   - [providers.output]   è¾“å‡ºProviderï¼ˆLayer 5: Renderingï¼‰
#
# âš ï¸ ä»¥ä¸‹æ—§é…ç½®èŠ‚å·²æ ‡è®°ä¸º DEPRECATEDï¼Œä»…ä¿ç•™å‘åå…¼å®¹ï¼š
#   - [understanding]  â†’ è¯·è¿ç§»åˆ° [providers.input]
#   - [expression]     â†’ è¯·è¿ç§»åˆ° [providers.output.expression_generator]
#   - [rendering]      â†’ è¯·è¿ç§»åˆ° [providers.output]
#   - [avatar]         â†’ è¯·è¿ç§»åˆ° [providers.output]
#   - [platform]       â†’ è¯·è¿ç§»åˆ° [providers.output.outputs.*]
#
# ğŸ”„ é…ç½®è¿ç§»å·¥å…·
# ç¨‹åºå¯åŠ¨æ—¶ä¼šè‡ªåŠ¨æ£€æµ‹å¹¶æç¤ºæ—§é…ç½®çš„ä½¿ç”¨ï¼Œå»ºè®®å°½å¿«è¿ç§»åˆ°æ–°æ ¼å¼ã€‚
#
# === å…¨å±€ LLM é…ç½® ===
# é‡è¦ï¼šè¿™æ˜¯é¡¹ç›®é€šç”¨çš„ LLM é…ç½®ï¼Œä¾›æ‰€æœ‰æ¨¡å—ä½¿ç”¨
[llm]
# æ ‡å‡† LLM é…ç½®ï¼ˆç”¨äºé«˜è´¨é‡ä»»åŠ¡ï¼‰
backend = "openai"              # openai | ollama | anthropic
model = "Pro/deepseek-ai/DeepSeek-V3.2"
temperature = 0.2
api_key = "your-api-key"                    # å¯é€‰ï¼Œå¦‚æœä¸è®¾ç½®å°†ä½¿ç”¨ç¯å¢ƒå˜é‡
base_url = "https://api.siliconflow.cn/v1/" # å¯é€‰ï¼Œç”¨äºè‡ªå®šä¹‰APIç«¯ç‚¹
max_tokens = 1024
max_retries = 3                 # å¯é€‰ï¼Œé»˜è®¤ 3
retry_delay = 1.0               # å¯é€‰ï¼Œé»˜è®¤ 1.0

[llm_fast]
# å¿«é€Ÿ LLM é…ç½®ï¼ˆç”¨äºä½å»¶è¿Ÿä»»åŠ¡ï¼Œå¦‚ Avatar è¡¨æƒ…åˆ†æï¼‰
backend = "openai"
model = "Qwen/Qwen3-8B"
temperature = 0.2
api_key = "your-api-key"                    # å¯é€‰ï¼Œå¦‚æœä¸è®¾ç½®å°†ä½¿ç”¨ç¯å¢ƒå˜é‡
base_url = "https://api.siliconflow.cn/v1/" # å¯é€‰ï¼Œç”¨äºè‡ªå®šä¹‰APIç«¯ç‚¹
max_tokens = 1024

[vlm]
# è§†è§‰è¯­è¨€æ¨¡å‹é…ç½®ï¼ˆç”¨äºå›¾åƒç†è§£ä»»åŠ¡ï¼‰
backend = "openai"
model = "zai-org/GLM-4.6V"
temperature = 0.3
api_key = "your-api-key"
base_url = "https://api.siliconflow.cn/v1/"
max_tokens = 1024

# å¯é€‰ï¼šæœ¬åœ° Ollama
[llm_local]
backend = "ollama"
model = "llama3"
api_base = "http://localhost:11434/v1"
api_key = "sk-dummy"            # Ollama ä¸éœ€è¦çœŸå® API key

# === Amaidesu æ ¸å¿ƒé…ç½® ===
[general]
# Amaidesu åœ¨ MaiCore ä¸­æ³¨å†Œçš„å¹³å°æ ‡è¯†ç¬¦
platform_id = "amaidesu"

[maicore]
# MaiCore WebSocket æœåŠ¡å™¨åœ°å€
host = "127.0.0.1"
# MaiCore WebSocket æœåŠ¡å™¨ç«¯å£
port = 8000
# token = "your_maicore_token_if_needed" # å¦‚æœ MaiCore éœ€è¦è®¤è¯ï¼Œå–æ¶ˆæ³¨é‡Šå¹¶è®¾ç½®

[spark_rtasr]
# è®¯é£ RTASR å®æ—¶è¯†åˆ«å‡­æ®
# app_id = ""
# access_key_id = ""
# access_key_secret = ""
# å¯é€‰ï¼šè‡ªå®šä¹‰ websocket URLï¼ˆé»˜è®¤å®˜æ–¹åœ°å€ï¼‰
# ws_url = "wss://office-api-ast-dx.iflyaisol.com/ast/communicate/v1"
app_id = ""
access_key_id = ""
access_key_secret = ""


[http_server]
# æ˜¯å¦å¯ç”¨æœ¬åœ° HTTP å›è°ƒæœåŠ¡å™¨
enable = true
# ç›‘å¬çš„ä¸»æœºåœ°å€
host = "127.0.0.1"
# ç›‘å¬çš„ç«¯å£
port = 8080
# MaiCore æˆ–å…¶ä»–æœåŠ¡è®¿é—®çš„å›è°ƒè·¯å¾„
callback_path = "/maicore_callback"

# ä¸Šä¸‹æ–‡ç®¡ç†å™¨é…ç½®
[context_manager]
enabled = true

# ä¸Šä¸‹æ–‡æ ¼å¼åŒ–é…ç½®
[context_manager.formatting]
separator = "\n"           # ä¸Šä¸‹æ–‡é¡¹ä¹‹é—´çš„åˆ†éš”ç¬¦
add_provider_title = false # æ˜¯å¦åœ¨ä¸Šä¸‹æ–‡å‰æ·»åŠ æä¾›è€…åç§°
title_separator = ": "     # å¦‚æœæ·»åŠ æä¾›è€…åç§°ï¼Œä½¿ç”¨çš„åˆ†éš”ç¬¦

# ä¸Šä¸‹æ–‡é•¿åº¦é™åˆ¶é…ç½®
[context_manager.limits]
default_max_length = 1000 # é»˜è®¤ä¸Šä¸‹æ–‡æœ€å¤§é•¿åº¦
default_priority = 100    # é»˜è®¤ä¼˜å…ˆçº§å€¼

# ========== ç®¡é“é…ç½® ==========
[pipelines]
# === TextPipelineï¼ˆæ–°æ¶æ„ï¼ŒLayer 2â†’3 æ–‡æœ¬é¢„å¤„ç†ï¼‰ ===
# TextPipeline åœ¨ NormalizedText â†’ CanonicalMessage ä¹‹é—´æ‰§è¡Œæ–‡æœ¬é¢„å¤„ç†

# ç¤ºä¾‹ï¼šå¯ç”¨é™æµç®¡é“ï¼ˆTextPipeline ç‰ˆæœ¬ï¼‰
# [pipelines.rate_limit]
# priority = 100        # æ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜
# global_rate_limit = 100  # å¯é€‰ï¼šå…¨å±€æ¯åˆ†é’Ÿæœ€å¤§æ¶ˆæ¯æ•°
# user_rate_limit = 10     # å¯é€‰ï¼šæ¯ä¸ªç”¨æˆ·æ¯åˆ†é’Ÿæœ€å¤§æ¶ˆæ¯æ•°
# window_size = 60         # å¯é€‰ï¼šæ»‘åŠ¨çª—å£å¤§å°ï¼ˆç§’ï¼‰

# ç¤ºä¾‹ï¼šå¯ç”¨ç›¸ä¼¼æ–‡æœ¬è¿‡æ»¤ç®¡é“ï¼ˆTextPipeline ç‰ˆæœ¬ï¼‰
# [pipelines.similar_text_filter]
# priority = 200
# similarity_threshold = 0.85  # å¯é€‰ï¼šç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆ0-1ï¼‰
# time_window = 60.0           # å¯é€‰ï¼šæ—¶é—´çª—å£ï¼ˆç§’ï¼‰
# max_cache_size = 1000       # å¯é€‰ï¼šæœ€å¤§ç¼“å­˜æ¡ç›®æ•°

# === MessagePipelineï¼ˆæ—§æ¶æ„ï¼Œinbound/outbound æ¶ˆæ¯å¤„ç†ï¼‰ ===
# MessagePipeline åœ¨ MaiCore æ¶ˆæ¯çš„å…¥ç«™/å‡ºç«™è·¯å¾„ä¸Šå¤„ç†

# ç¤ºä¾‹ï¼šå¯ç”¨ message_logger ç®¡é“
# [pipelines.message_logger]
# priority = 200
# log_dir = "data/message_logs"  # å¯é€‰ï¼šæ—¥å¿—ç›®å½•

# ç¤ºä¾‹ï¼šå¯ç”¨ command_processor ç®¡é“ (å…¥ç«™)
[pipelines.command_processor]
# è¿™æ˜¯ä¸€ä¸ªå…¥ç«™ç®¡é“ï¼Œç”¨äºå¤„ç†å’Œæ‰§è¡Œæ¥è‡ª MaiCore æ¶ˆæ¯ä¸­çš„å‘½ä»¤
# ä¾‹å¦‚ï¼Œæ‰§è¡Œ VTubeStudio çƒ­é”®ï¼Œç„¶åä»æ–‡æœ¬ä¸­ç§»é™¤å‘½ä»¤æ ‡è®°
priority = 50
# direction = "inbound" # æ­¤ç®¡é“çš„ direction å·²åœ¨å…¶è‡ªå·±çš„ config ä¸­è®¾ç½®ï¼Œæ­¤å¤„æ— éœ€é‡å¤
# å¯ä»¥åœ¨æ­¤è¦†ç›– command_map
# command_map = { vts_trigger_hotkey = { service = "vts_control", method = "trigger_hotkey" } }

# ========== Provideré…ç½® ==========

# Provideré…ç½®ç»Ÿä¸€ç®¡ç†
# æ­¤é…ç½®ç”¨äºç»Ÿä¸€ç®¡ç†æ‰€æœ‰Providerï¼ˆInputã€Outputã€Decisionï¼‰

# === è¾“å…¥Provideré…ç½®ï¼ˆLayer 1: Perceptionï¼‰ ===
[providers.input]
# æ˜¯å¦å¯ç”¨è¾“å…¥å±‚
enabled = true
# å¯ç”¨çš„è¾“å…¥Provideråˆ—è¡¨
enabled_inputs = [
    # æ§åˆ¶å°è¾“å…¥ï¼ˆå¼€å‘æµ‹è¯•ç”¨ï¼‰
    # "console_input",

    # Bç«™å¼¹å¹•è¾“å…¥
    # "bili_danmaku",           # æ™®é€šBç«™å¼¹å¹•
    # "bili_danmaku_official",  # Bç«™å®˜æ–¹å¼¹å¹•ï¼ˆä¸è¦å’Œbili_danmakuåŒæ—¶å¯ç”¨ï¼‰
    # "bili_danmaku_selenium",  # Bç«™å¼¹å¹•-Seleniumç‰ˆ

    # å…¶ä»–è¾“å…¥
    # "mock_danmaku",           # æ¨¡æ‹Ÿå¼¹å¹•
    # "read_pingmu",            # è¯»å±æœ¨
]

# å„ä¸ªInputProviderçš„è¯¦ç»†é…ç½®
[providers.input.inputs.console_input]
type = "console_input"
# å¯é€‰ï¼šæ·»åŠ è‡ªå®šä¹‰é…ç½®

[providers.input.inputs.bili_danmaku]
type = "bili_danmaku"
room_id = ""          # Bç«™ç›´æ’­é—´å·
# ... å…¶ä»–Bç«™å¼¹å¹•é…ç½®

[providers.input.inputs.mock_danmaku]
type = "mock_danmaku"
# æ¨¡æ‹Ÿå¼¹å¹•é…ç½®

# === è¾“å‡ºProvideré…ç½®ï¼ˆLayer 7: Renderingï¼‰ ===
[providers.output]
# æ˜¯å¦å¯ç”¨è¾“å‡ºå±‚
enabled = true
# æ˜¯å¦å¹¶å‘æ¸²æŸ“åˆ°æ‰€æœ‰Provider
concurrent_rendering = true
# é”™è¯¯å¤„ç†ç­–ç•¥ï¼šcontinueï¼ˆç»§ç»­ï¼‰ã€stopï¼ˆåœæ­¢ï¼‰ã€dropï¼ˆä¸¢å¼ƒï¼‰
error_handling = "continue"

# å¯ç”¨çš„è¾“å‡ºProvideråˆ—è¡¨
enabled_outputs = [
    # åŸºç¡€è¾“å‡ºï¼ˆæ¨èå¯ç”¨ï¼‰
    "subtitle",     # å­—å¹•
    "vts",          # VTSæ§åˆ¶

    # TTSè¾“å‡ºï¼ˆé€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªï¼‰
    # "tts",         # Edge TTS
    # "omni_tts",    # Omni TTS (GPT-SoVITS)

    # å…¶ä»–è¾“å‡º
    # "sticker",     # è¡¨æƒ…è´´çº¸
]

# ExpressionGeneratoré…ç½®
[providers.output.expression_generator]
# é»˜è®¤TTSæ˜¯å¦å¯ç”¨
default_tts_enabled = true
# é»˜è®¤å­—å¹•æ˜¯å¦å¯ç”¨
default_subtitle_enabled = true
# é»˜è®¤è¡¨æƒ…æ˜¯å¦å¯ç”¨
default_expressions_enabled = true
# é»˜è®¤çƒ­é”®æ˜¯å¦å¯ç”¨
default_hotkeys_enabled = true

# å„ä¸ªOutputProviderçš„è¯¦ç»†é…ç½®

# TTS Provideré…ç½®
[providers.output.outputs.tts]
type = "tts"
# TTSå¼•æ“ï¼šedge æˆ– omni
engine = "edge"
# Edge TTSè¯­éŸ³
voice = "zh-CN-XiaoxiaoNeural"
# éŸ³é¢‘è¾“å‡ºè®¾å¤‡åç§°ï¼ˆç•™ç©ºä½¿ç”¨é»˜è®¤è®¾å¤‡ï¼‰
output_device_name = ""

# Omni TTSé…ç½®ï¼ˆä»…åœ¨engine=omniæ—¶ç”Ÿæ•ˆï¼‰
[providers.output.outputs.tts.omni]
# Omni TTS APIåœ°å€
api_url = "http://localhost:9880"
# æ¨¡å‹åç§°
model = "path/to/model"
# è¯´è¯äººID
speaker = 0
# è¯­é€Ÿ
speed = 1.0
# éŸ³è°ƒ
pitch = 1.0
# éŸ³é‡
volume = 1.0

# Subtitle Provideré…ç½®
[providers.output.outputs.subtitle]
type = "subtitle"
# å­—å¹•çª—å£å®½åº¦
window_width = 800
# å­—å¹•çª—å£é«˜åº¦
window_height = 100
# å­—ä½“å¤§å°
font_size = 24
# å­—ä½“é¢œè‰²
font_color = "#FFFFFF"
# èƒŒæ™¯é¢œè‰²
bg_color = "#000000"
# èƒŒæ™¯é€æ˜åº¦ï¼ˆ0-255ï¼‰
bg_alpha = 180
# å­—å¹•æ˜¾ç¤ºä½ç½®ï¼ˆtop/center/bottomï¼‰
position = "bottom"
# è‡ªåŠ¨éšè—å»¶è¿Ÿï¼ˆç§’ï¼Œ0è¡¨ç¤ºä¸éšè—ï¼‰
auto_hide_delay = 5.0
# æ˜¯å¦å¯ç”¨æ‹–æ‹½
draggable = true
# æ˜¯å¦å¯ç”¨Chroma-keyï¼ˆOBSæŠ å›¾ï¼‰
chroma_key_enabled = false
# Chroma-keyé¢œè‰²
chroma_key_color = "#00FF00"

# Sticker Provideré…ç½®
[providers.output.outputs.sticker]
type = "sticker"
# è´´çº¸å¤§å°ï¼ˆç›¸å¯¹äºçª—å£å®½åº¦çš„æ¯”ä¾‹ï¼Œ0-1ï¼‰
sticker_size = 0.33
# è´´çº¸æ—‹è½¬è§’åº¦ï¼ˆåº¦ï¼‰
sticker_rotation = 0
# è´´çº¸æ˜¾ç¤ºæ—¶é•¿ï¼ˆç§’ï¼‰
display_duration = 3.0
# è´´çº¸å†·å´æ—¶é—´ï¼ˆç§’ï¼Œé˜²æ­¢åˆ·å±ï¼‰
cooldown = 5.0
# è´´çº¸ç›®å½•
sticker_dir = "data/stickers"
# é»˜è®¤è´´çº¸ï¼ˆå½“æ²¡æœ‰å…³é”®è¯åŒ¹é…æ—¶ä½¿ç”¨ï¼‰
default_sticker = "default.png"

# VTS Provideré…ç½®
[providers.output.outputs.vts]
type = "vts"
# VTS WebSocketåœ°å€
vts_host = "localhost"
vts_port = 8001
# æ˜¯å¦è‡ªåŠ¨è¿æ¥
auto_connect = true
# è¿æ¥è¶…æ—¶ï¼ˆç§’ï¼‰
connect_timeout = 10.0
# é‡è¿é—´éš”ï¼ˆç§’ï¼‰
reconnect_interval = 5.0
# æ˜¯å¦å¯ç”¨LLMæ™ºèƒ½çƒ­é”®åŒ¹é…
llm_matching_enabled = false
# LLMé…ç½®ï¼ˆå¯é€‰ï¼Œä¸è®¾ç½®åˆ™ä½¿ç”¨å…¨å±€llmé…ç½®ï¼‰
# llm_type = "llm_fast"  # llm, llm_fast, vlm
# max_hotkey_candidates = 5

# Omni TTS Provideré…ç½®
[providers.output.outputs.omni_tts]
type = "omni_tts"
# Omni TTS APIåœ°å€
api_url = "http://localhost:9880"
# æ¨¡å‹è·¯å¾„
model_path = "path/to/model"
# è¯´è¯äººID
speaker_id = 0
# è¯­é€Ÿ
speed = 1.0
# éŸ³è°ƒ
pitch = 1.0
# éŸ³é‡
volume = 1.0
# éŸ³é¢‘è¾“å‡ºè®¾å¤‡åç§°ï¼ˆç•™ç©ºä½¿ç”¨é»˜è®¤è®¾å¤‡ï¼‰
output_device_name = ""
# æ˜¯å¦å¯ç”¨æµå¼TTS
stream_enabled = true
# ç¼“å­˜ç›®å½•
cache_dir = "data/omni_tts_cache"
# æœ€å¤§ç¼“å­˜æ•°é‡ï¼ˆ0è¡¨ç¤ºä¸é™åˆ¶ï¼‰
max_cache_size = 100

# === å†³ç­–Provideré…ç½®ï¼ˆLayer 4: Decisionï¼‰ ===
[providers.decision]
# æ˜¯å¦å¯ç”¨å†³ç­–å±‚
enabled = true
# å½“å‰ä½¿ç”¨çš„å†³ç­–Providerï¼ˆactive providerï¼‰
active_provider = "maicore"
# æ”¯æŒçš„å†³ç­–Provideråˆ—è¡¨
available_providers = [
    "maicore",        # MaiCoreå†³ç­–ï¼ˆé»˜è®¤ï¼‰
    "rule_engine",    # è§„åˆ™å¼•æ“
    "local_llm",      # æœ¬åœ°LLM
]

# å„ä¸ªDecisionProviderçš„è¯¦ç»†é…ç½®

# MaiCoreå†³ç­–Provideré…ç½®
[providers.decision.providers.maicore]
type = "maicore"
# WebSocketè¿æ¥é…ç½®
host = "127.0.0.1"
port = 8000
# token = "your_token_if_needed"
# è¿æ¥è¶…æ—¶ï¼ˆç§’ï¼‰
connect_timeout = 10.0
# é‡è¿é—´éš”ï¼ˆç§’ï¼‰
reconnect_interval = 5.0

# è§„åˆ™å¼•æ“å†³ç­–Provideré…ç½®
[providers.decision.providers.rule_engine]
type = "rule_engine"
# è§„åˆ™æ–‡ä»¶è·¯å¾„
rules_file = "data/rules/decision_rules.toml"
# é»˜è®¤å›å¤
default_response = "æˆ‘ä¸çŸ¥é“æ€ä¹ˆå›ç­”è¿™ä¸ªé—®é¢˜"

# æœ¬åœ°LLMå†³ç­–Provideré…ç½®
[providers.decision.providers.local_llm]
type = "local_llm"
# LLMç±»å‹ï¼ˆllm, llm_fast, vlmï¼‰
llm_type = "llm"
# è‡ªå®šä¹‰æ¨¡å‹é…ç½®ï¼ˆå¯é€‰ï¼Œä¸è®¾ç½®åˆ™ä½¿ç”¨å…¨å±€é…ç½®ï¼‰
# model = "gpt-4"
# api_key = "your-api-key"
# base_url = "https://api.openai.com/v1"
# temperature = 0.7
# max_tokens = 1000
# ç³»ç»Ÿæç¤ºè¯
system_prompt = "ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ï¼Œè¯·ç®€æ´åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"

