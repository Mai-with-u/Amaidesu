# Phase 3: å†³ç­–å±‚ + Layer 3-4

## ğŸ¯ ç›®æ ‡

å®ç°ï¼š
1. **å†³ç­–å±‚**ï¼šå¯æ›¿æ¢çš„å†³ç­–Providerç³»ç»Ÿ
2. **Layer 3: ä¸­é—´è¡¨ç¤ºå±‚**ï¼šç»Ÿä¸€æ¶ˆæ¯æ ¼å¼
3. **Layer 4: è¡¨ç°ç†è§£å±‚**ï¼šè§£æMessageBase â†’ Intent

## ğŸ“ ç›®å½•ç»“æ„

```
src/
â”œâ”€â”€ canonical/                         # Layer 3: ä¸­é—´è¡¨ç¤º
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ canonical_message.py
â”‚   â”œâ”€â”€ message_builder.py
â”‚   â””â”€â”€ maicore_adapter.py            # MaiCoreé€‚é…å™¨
â”‚
â”œâ”€â”€ understanding/                     # Layer 4: è¡¨ç°ç†è§£
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ response_parser.py
â”‚   â”œâ”€â”€ text_cleanup.py
â”‚   â””â”€â”€ emotion_judge.py
â”‚
â””â”€â”€ core/
    â”œâ”€â”€ decision_manager.py             # å†³ç­–ç®¡ç†å™¨ï¼ˆæ–°å¢ï¼‰
    â””â”€â”€ providers/                     # å†³ç­–Providerå®ç°
        â”œâ”€â”€ maicore_decision_provider.py    # MaiCoreå†³ç­–Provider
        â”œâ”€â”€ local_llm_decision_provider.py   # æœ¬åœ°LLMå†³ç­–Provider
        â””â”€â”€ rule_engine_decision_provider.py # è§„åˆ™å¼•æ“å†³ç­–Provider
```

## ğŸ“ å®æ–½å†…å®¹

### 3.1 Layer 3: ä¸­é—´è¡¨ç¤ºå±‚

#### åˆ›å»ºCanonicalMessage

`src/canonical/canonical_message.py`:
```python
import time
from typing import Dict, Any

class CanonicalMessage:
    """æ ‡å‡†åŒ–æ¶ˆæ¯æ ¼å¼ - Layer 3çš„è¾“å‡ºæ ¼å¼"""

    def __init__(
        self,
        text: str,
        source: str,
        user_id: str = None,
        user_name: str = None,
        timestamp: float = None,
        metadata: Dict[str, Any] = None
    ):
        self.text = text
        self.source = source
        self.user_id = user_id
        self.user_name = user_name
        self.timestamp = timestamp or time.time()
        self.metadata = metadata or {}

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "text": self.text,
            "source": self.source,
            "user_id": self.user_id,
            "user_name": self.user_name,
            "timestamp": self.timestamp,
            "metadata": self.metadata
        }
```

`src/canonical/message_builder.py`:
```python
from typing import Dict, Any
from src.canonical.canonical_message import CanonicalMessage

class MessageBuilder:
    """æ¶ˆæ¯æ„å»ºå™¨ - ä¾¿æ·åˆ›å»ºCanonicalMessage"""

    @staticmethod
    def create_from_text(text: str, source: str, **metadata) -> CanonicalMessage:
        """ä»æ–‡æœ¬åˆ›å»ºæ¶ˆæ¯"""
        return CanonicalMessage(
            text=text,
            source=source,
            **metadata
        )

    @staticmethod
    def create_from_dict(data: Dict[str, Any]) -> CanonicalMessage:
        """ä»å­—å…¸åˆ›å»ºæ¶ˆæ¯"""
        return CanonicalMessage(
            text=data.get("text", ""),
            source=data.get("source", "unknown"),
            user_id=data.get("user_id"),
            user_name=data.get("user_name"),
            timestamp=data.get("timestamp"),
            metadata=data.get("metadata", {})
        )
```

### 3.2 å†³ç­–å±‚å®ç°

#### MaiCoreå†³ç­–Provider

`src/core/providers/maicore_decision_provider.py`:
```python
from maim_message import MessageBase
from src.core.decision_provider import DecisionProvider, CanonicalMessage
from src.core.amaidesu_core import AmaidesuCore
from src.utils.logger import get_logger

class MaiCoreDecisionProvider:
    """MaiCoreå†³ç­–Providerï¼ˆé»˜è®¤å®ç°ï¼‰"""

    def __init__(self, config: dict):
        self.config = config
        self.core: AmaidesuCore = None
        self.logger = get_logger("MaiCoreDecisionProvider")

    async def setup(self, event_bus, config: dict):
        """åˆå§‹åŒ–MaiCoreè¿æ¥"""
        # AmaidesuCoreä¼šåœ¨å¤–éƒ¨ä¼ å…¥
        self.logger.info("MaiCoreDecisionProvider setup complete")

    async def decide(self, canonical_message: CanonicalMessage) -> MessageBase:
        """å‘é€ç»™MaiCoreè¿›è¡Œå†³ç­–"""
        self.logger.info(f"Sending to MaiCore: {canonical_message.text[:50]}...")

        # æ„å»ºMessageBase
        # è¿™é‡Œéœ€è¦è°ƒç”¨AmaidesuCoreçš„æ–¹æ³•å‘é€ç»™MaiCore
        # å®é™…å®ç°ä¼šé€šè¿‡AmaidesuCoreå‘é€åˆ°MaiCore WebSocket

        # è¿”å›MessageBaseï¼ˆæ¨¡æ‹Ÿï¼‰
        from maim_message import MessageBase, BaseMessageInfo, UserInfo, Seg, FormatInfo
        message_info = BaseMessageInfo(
            platform="amaidesu",
            message_id=f"maicore_{int(time.time() * 1000)}",
            time=time.time(),
            user_info=UserInfo(
                platform="amaidesu",
                user_id=canonical_message.user_id or "unknown",
                user_nickname=canonical_message.user_name or "User"
            ),
            format_info=FormatInfo(
                content_format=["text"],
                accept_format=["text"]
            )
        )

        message_segment = Seg(type="text", data="è¿™æ˜¯MaiCoreçš„å›å¤æ–‡æœ¬")

        return MessageBase(
            message_info=message_info,
            message_segment=message_segment,
            raw_message="è¿™æ˜¯MaiCoreçš„å›å¤æ–‡æœ¬"
        )

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.logger.info("MaiCoreDecisionProvider cleanup")
```

#### æœ¬åœ°LLMå†³ç­–Providerï¼ˆç¤ºä¾‹ï¼‰

`src/core/providers/local_llm_decision_provider.py`:
```python
from maim_message import MessageBase
from src.core.decision_provider import DecisionProvider, CanonicalMessage
from src.utils.logger import get_logger

class LocalLLMDecisionProvider:
    """æœ¬åœ°LLMå†³ç­–Providerï¼ˆå¯é€‰å®ç°ï¼‰"""

    def __init__(self, config: dict):
        self.config = config
        self.model = config.get("model", "gpt-4")
        self.api_key = config.get("api_key")
        self.logger = get_logger("LocalLLMDecisionProvider")

    async def setup(self, event_bus, config: dict):
        """åˆå§‹åŒ–LLMå®¢æˆ·ç«¯"""
        self.logger.info(f"LocalLLMDecisionProvider setup with model: {self.model}")

    async def decide(self, canonical_message: CanonicalMessage) -> MessageBase:
        """ä½¿ç”¨æœ¬åœ°LLMè¿›è¡Œå†³ç­–"""
        self.logger.info(f"Using local LLM: {canonical_message.text[:50]}...")

        # è°ƒç”¨æœ¬åœ°LLM API
        # response_text = await self._call_llm(canonical_message.text)

        response_text = "è¿™æ˜¯æœ¬åœ°LLMçš„å›å¤"

        # æ„å»ºMessageBase
        from maim_message import MessageBase, BaseMessageInfo, UserInfo, Seg, FormatInfo
        message_info = BaseMessageInfo(
            platform="amaidesu",
            message_id=f"local_llm_{int(time.time() * 1000)}",
            time=time.time(),
            user_info=UserInfo(
                platform="amaidesu",
                user_id=canonical_message.user_id or "unknown",
                user_nickname=canonical_message.user_name or "User"
            ),
            format_info=FormatInfo(
                content_format=["text"],
                accept_format=["text"]
            )
        )

        message_segment = Seg(type="text", data=response_text)

        return MessageBase(
            message_info=message_info,
            message_segment=message_segment,
            raw_message=response_text
        )

    async def _call_llm(self, prompt: str) -> str:
        """è°ƒç”¨LLM API"""
        # å®é™…å®ç°ä¼šè°ƒç”¨OpenAI APIæˆ–å…¶ä»–LLM API
        return "è¿™æ˜¯LLMç”Ÿæˆçš„å›å¤"

    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.logger.info("LocalLLMDecisionProvider cleanup")
```

### 3.3 Layer 4: è¡¨ç°ç†è§£å±‚

#### å“åº”è§£æå™¨

`src/understanding/response_parser.py`:
```python
from typing import Protocol
from maim_message import MessageBase

class Intent:
    """æ„å›¾å¯¹è±¡ - Layer 4çš„è¾“å‡ºæ ¼å¼"""

    def __init__(
        self,
        original_text: str,
        emotion: str = "NEUTRAL",
        response_text: str = "",
        actions: list = None,
        metadata: dict = None
    ):
        self.original_text = original_text
        self.emotion = emotion
        self.response_text = response_text
        self.actions = actions or []
        self.metadata = metadata or {}

class ResponseParser(Protocol):
    """å“åº”è§£æå™¨åè®® - Layer 4"""

    async def parse(self, message: MessageBase) -> Intent:
        """è§£æMessageBaseç”ŸæˆIntent"""
        ...
```

`src/understanding/emotion_judge.py`:
```python
from maim_message import MessageBase
from src.understanding.response_parser import Intent, ResponseParser
from src.utils.logger import get_logger

class EmotionJudgeProvider:
    """æƒ…æ„Ÿåˆ¤æ–­Provider"""

    def __init__(self, config: dict):
        self.config = config
        self.logger = get_logger("EmotionJudgeProvider")

    async def parse(self, message: MessageBase) -> Intent:
        """è§£ææ¶ˆæ¯å¹¶åˆ¤æ–­æƒ…æ„Ÿ"""
        text = ""
        if message.message_segment and message.message_segment.type == "text":
            text = message.message_segment.data

        # åˆ¤æ–­æƒ…æ„Ÿ
        emotion = await self._judge_emotion(text)

        return Intent(
            original_text=text,
            emotion=emotion,
            response_text=text,
            metadata={"source": "emotion_judge"}
        )

    async def _judge_emotion(self, text: str) -> str:
        """åˆ¤æ–­æ–‡æœ¬æƒ…æ„Ÿ"""
        # ç®€å•å®ç°ï¼ˆå®é™…åº”ä½¿ç”¨æ›´å¤æ‚çš„ç®—æ³•ï¼‰
        positive_keywords = ["å¼€å¿ƒ", "é«˜å…´", "å“ˆå“ˆ", "æ£’", "å¥½"]
        negative_keywords = ["éš¾è¿‡", "ä¼¤å¿ƒ", "ä¸å¥½", "è®¨åŒ"]

        for keyword in positive_keywords:
            if keyword in text:
                return "HAPPY"

        for keyword in negative_keywords:
            if keyword in text:
                return "SAD"

        return "NEUTRAL"
```

## âœ… éªŒè¯æ ‡å‡†

1. âœ… CanonicalMessageå¯ä»¥æ­£ç¡®æ„å»ºå’Œè½¬æ¢
2. âœ… MaiCoreDecisionProviderå¯ä»¥å‘é€æ¶ˆæ¯åˆ°MaiCore
3. âœ… LocalLLMDecisionProviderå¯ä»¥è°ƒç”¨æœ¬åœ°LLM
4. âœ… ResponseParserå¯ä»¥è§£æMessageBaseç”ŸæˆIntent
5. âœ… EmotionJudgeå¯ä»¥æ­£ç¡®åˆ¤æ–­æƒ…æ„Ÿ
6. âœ… å†³ç­–å±‚å¯ä»¥åˆ‡æ¢ä¸åŒçš„DecisionProvider

## ğŸ“ æäº¤

```bash
git add src/canonical/ src/understanding/ src/core/decision_manager.py src/core/providers/

git commit -m "feat(phase3): implement decision layer and Layer 3-4"
```
