# Amaidesu é‡æ„å®æ–½è®¡åˆ’

## ğŸ¯ å®æ–½åŸåˆ™

### æ ¸å¿ƒç›®æ ‡
1. **å…¨é¢é‡æ„**ï¼š1-2å¤©å†…å®Œæˆï¼Œä¸è€ƒè™‘å‘åå…¼å®¹
2. **æ¶ˆç­æ’ä»¶åŒ–**ï¼šæ ¸å¿ƒåŠŸèƒ½å…¨éƒ¨æ¨¡å—åŒ–
3. **EventBusä¼˜å…ˆ**ï¼šç”¨äº‹ä»¶ç³»ç»Ÿæ›¿ä»£æœåŠ¡æ³¨å†Œ
4. **ç­–ç•¥æ¨¡å¼**ï¼šç»Ÿä¸€æ¥å£ï¼Œå·¥å‚åŠ¨æ€é€‰æ‹©

### å®æ–½é¡ºåº
æŒ‰ç…§æ•°æ®æµé¡ºåºï¼Œä»è¾“å…¥åˆ°è¾“å‡ºé€æ­¥é‡æ„ï¼š
```
Layer 1 â†’ Layer 2 â†’ Layer 3 â†’ Layer 4 â†’ Layer 5 â†’ Layer 6 â†’ Layer 7
```

## ğŸ“‹ åˆ†å±‚å®æ–½è®¡åˆ’

### Phase 1: åŸºç¡€è®¾æ–½æ­å»º

#### 1.1 åˆ›å»º7å±‚ç›®å½•ç»“æ„
```
src/
â”œâ”€â”€ perception/
â”œâ”€â”€ normalization/  
â”œâ”€â”€ canonical/
â”œâ”€â”€ understanding/
â”œâ”€â”€ expression/
â”œâ”€â”€ rendering/
â””â”€â”€ integration/
```

#### 1.2 ç­–ç•¥æ¨¡å¼åŸºç¡€è®¾æ–½
```python
# åˆ›å»ºåŸºç¡€ç±»
src/core/strategies/base_strategy.py
src/core/factories/strategy_factory.py
src/core/module_loader.py
```

#### 1.3 äº‹ä»¶ç³»ç»Ÿå¢å¼º
```python
# å®Œå–„EventBus
src/core/event_bus.py  # å¢å¼ºäº‹ä»¶è·¯ç”±å’Œé”™è¯¯å¤„ç†
```

### Phase 2: Layer 1-2 å®ç°

#### 2.1 è¾“å…¥æ„ŸçŸ¥å±‚(Layer 1)
**ç›®æ ‡**ï¼šç»Ÿä¸€æ‰€æœ‰è¾“å…¥æºæ¥å£

**å®æ–½æ­¥éª¤**ï¼š
1. åˆ›å»ºè¾“å…¥æºåŸºç±»
   ```python
   # src/perception/base_input.py
   from typing import Protocol, AsyncIterator, TypedDict

   class RawData(TypedDict):
       """åŸå§‹æ•°æ®åŸºç±»"""
       content: Any
       timestamp: float
       source: str
       metadata: dict

   class InputSource(Protocol):
       """è¾“å…¥æºåè®®"""
       
       async def start(self) -> AsyncIterator[RawData]:
           """å¯åŠ¨è¾“å…¥æµ,è¿”å›åŸå§‹æ•°æ®"""
           ...
       
       async def stop(self):
           """åœæ­¢è¾“å…¥æº"""
           ...
       
       def get_source_type(self) -> str:
           """è·å–è¾“å…¥æºç±»å‹"""
           ...
   ```

2. è¿ç§»ç°æœ‰è¾“å…¥æºï¼š
   - `console_input` â†’ `src/perception/text/console_input.py`
   - `bili_danmaku` â†’ `src/perception/text/danmaku/bilibili.py`
   - `mock_danmaku` â†’ `src/perception/text/danmaku/mock.py`
   - `stt` â†’ `src/perception/audio/stt.py`

3. åˆ›å»ºè¾“å…¥æºå·¥å‚ï¼š
   ```python
   # src/perception/input_factory.py
   from typing import Dict, Any, Protocol
   from src.core.factories.strategy_factory import StrategyFactory

   class InputFactory(StrategyFactory):
       """è¾“å…¥æºå·¥å‚"""
       
       def __init__(self):
           super().__init__()
           self._register_all_inputs()
       
       def _register_all_inputs(self):
           """æ³¨å†Œæ‰€æœ‰è¾“å…¥æº"""
           # æ³¨å†Œæ–‡æœ¬è¾“å…¥
           self.register_strategy("console", ConsoleInputStrategy, is_default=True)
           self.register_strategy("bilibili", BilibiliDanmakuStrategy)
           self.register_strategy("mock", MockDanmakuStrategy)
           
           # æ³¨å†ŒéŸ³é¢‘è¾“å…¥
           self.register_strategy("stt", STTStrategy)
       
       def create_input_source(self, provider: str, config: Dict[str, Any]) -> InputSource:
           """åˆ›å»ºè¾“å…¥æºå®ä¾‹"""
           return self.create_strategy(provider, config)
   ```

#### 2.2 è¾“å…¥æ ‡å‡†åŒ–å±‚(Layer 2)
**ç›®æ ‡**ï¼šæ‰€æœ‰è¾“å…¥ç»Ÿä¸€è½¬æ¢ä¸ºText

**å®æ–½æ­¥éª¤**ï¼š
1. åˆ›å»ºæ ‡å‡†åŒ–å™¨æ¥å£ï¼š
   ```python
   # src/normalization/base_normalizer.py
   from typing import Protocol
   from src.perception.base_input import RawData

   class Normalizer(Protocol):
       """æ ‡å‡†åŒ–å™¨åè®®"""
       
       async def normalize(self, raw_data: RawData) -> str:
           """å°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºæ–‡æœ¬"""
           ...
   ```

2. å®ç°å…·ä½“æ ‡å‡†åŒ–å™¨ï¼š
   ```python
   # src/normalization/text_normalizer.py
   from typing import Dict, Any
   from src.core.strategies.base_strategy import BaseStrategy

   class TextNormalizer(BaseStrategy):
       """æ–‡æœ¬æ ‡å‡†åŒ–å™¨"""
       
       async def initialize(self) -> bool:
           self.clean_rules = self.config.get("clean_rules", [])
           self.logger.info("æ–‡æœ¬æ ‡å‡†åŒ–å™¨åˆå§‹åŒ–æˆåŠŸ")
           return True
       
       async def normalize(self, raw_data: RawData) -> str:
           """æ–‡æœ¬æ ‡å‡†åŒ–å¤„ç†"""
           if raw_data["source"] != "text":
               return ""
           
           text = raw_data["content"]
           
           # åº”ç”¨æ¸…ç†è§„åˆ™
           for rule in self.clean_rules:
               pattern = rule.get("pattern")
               replacement = rule.get("replacement", "")
               text = re.sub(pattern, replacement, text)
           
           return text.strip()

   # src/normalization/audio_to_text.py
   class AudioToTextNormalizer(BaseStrategy):
       """éŸ³é¢‘â†’æ–‡æœ¬è½¬æ¢å™¨(STT)"""
       
       async def initialize(self) -> bool:
           try:
               from ...normalization.implementations.edge_stt import EdgeSTTEngine
               self.stt_engine = EdgeSTTEngine(self.config)
               await self.stt_engine.initialize()
               return True
           except Exception as e:
               self.logger.error(f"STTå¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
               return False
       
       async def normalize(self, raw_data: RawData) -> str:
           if raw_data["source"] != "audio":
               return ""
           
           # è°ƒç”¨STTè¯†åˆ«
           text = await self.stt_engine.recognize(raw_data["content"])
           return text
   ```

3. è‡ªåŠ¨è·¯ç”±æ ‡å‡†åŒ–ï¼š
   ```python
   # src/normalization/auto_normalizer.py
   from src.normalization.base_normalizer import Normalizer

   class AutoNormalizer:
       """è‡ªåŠ¨æ ‡å‡†åŒ–è·¯ç”±å™¨"""
       
       def __init__(self, config: Dict[str, Any]):
           self.factory = NormalizationFactory()
           self.logger = self._get_logger()
       
       async def normalize(self, raw_data: RawData) -> str:
           """æ ¹æ®æ•°æ®ç±»å‹è‡ªåŠ¨é€‰æ‹©æ ‡å‡†åŒ–å™¨"""
           source_type = raw_data["source"]
           
           # æ ¹æ®æºç±»å‹é€‰æ‹©æ ‡å‡†åŒ–å™¨
           if source_type == "text":
               normalizer = self.factory.create_normalizer("text", self.config)
           elif source_type == "audio":
               normalizer = self.factory.create_normalizer("audio", self.config)
           elif source_type == "image":
               normalizer = self.factory.create_normalizer("image", self.config)
           else:
               self.logger.warning(f"æœªçŸ¥çš„æ•°æ®ç±»å‹: {source_type}")
               return ""
           
           return await normalizer.normalize(raw_data)
   ```

### Phase 3: Layer 3-4 å®ç°

#### 3.1 ä¸­é—´è¡¨ç¤ºå±‚(Layer 3)
**ç›®æ ‡**ï¼šç»Ÿä¸€å†…éƒ¨æ¶ˆæ¯æ ¼å¼

**å®æ–½æ­¥éª¤**ï¼š
1. å®šä¹‰CanonicalMessageï¼š
   ```python
   # src/canonical/canonical_message.py
   from typing import TypedDict, Optional, Protocol
   from dataclasses import dataclass

   @dataclass
   class MessageMetadata(TypedDict):
       """æ¶ˆæ¯å…ƒæ•°æ®"""
       source: str
       timestamp: float
       user_id: Optional[str] = None
       user_name: Optional[str] = None
       platform: str = "unknown"
       room_id: Optional[int] = None

   @dataclass
   class ConversationContext(TypedDict):
       """å¯¹è¯ä¸Šä¸‹æ–‡"""
       history: list[dict]
       current_turn: int
       max_history: int

   class CanonicalMessage:
       """ç»Ÿä¸€æ¶ˆæ¯æ ¼å¼"""
       
       def __init__(self):
           self.text: str = ""              # æ–‡æœ¬å†…å®¹(Layer 2è¾“å‡º)
           self.metadata: MessageMetadata = MessageMetadata(
               source="",
               timestamp=0.0
           )  # å…ƒæ•°æ®
           self.context: Optional[ConversationContext] = None  # å¯¹è¯ä¸Šä¸‹æ–‡
       
       @classmethod
       def from_text(cls, text: str, source: str, **metadata) -> "CanonicalMessage":
           """ä»æ–‡æœ¬åˆ›å»ºæ¶ˆæ¯"""
           msg = cls()
           msg.text = text
           msg.metadata = MessageMetadata(
               source=source,
               timestamp=time.time(),
               **metadata
           )
           return msg
       
       @classmethod
       def from_dict(cls, data: dict) -> "CanonicalMessage":
           """ä»å­—å…¸åˆ›å»ºæ¶ˆæ¯"""
           msg = cls()
           msg.text = data.get("text", "")
           msg.metadata = MessageMetadata(**data.get("metadata", {}))
           
           # å¤„ç†ä¸Šä¸‹æ–‡
           if "context" in data:
               msg.context = ConversationContext(**data["context"])
           
           return msg
       
       def to_dict(self) -> dict:
           """è½¬æ¢ä¸ºå­—å…¸"""
           return {
               "text": self.text,
               "metadata": self.metadata,
               "context": self.context
           }
   ```

2. åˆ›å»ºæ¶ˆæ¯æ„å»ºå™¨ï¼š
   ```python
   # src/canonical/message_builder.py
   from typing import Dict, Any, Optional
   from src.canonical.canonical_message import CanonicalMessage, MessageMetadata

   class MessageBuilder:
       """æ¶ˆæ¯æ„å»ºå™¨"""
       
       @staticmethod
       def create_from_text(
           text: str,
           source: str,
           user_id: Optional[str] = None,
           user_name: Optional[str] = None,
           **kwargs
       ) -> CanonicalMessage:
           """ä»æ–‡æœ¬åˆ›å»ºæ¶ˆæ¯"""
           return CanonicalMessage.from_text(
               text=text,
               source=source,
               user_id=user_id,
               user_name=user_name,
               **kwargs
           )
       
       @staticmethod
       def create_from_raw(
           raw_data: Dict[str, Any],
           **metadata
       ) -> CanonicalMessage:
           """ä»åŸå§‹æ•°æ®åˆ›å»ºæ¶ˆæ¯"""
           return CanonicalMessage.from_dict({
               "text": raw_data.get("content", ""),
               "metadata": {
                   "source": raw_data.get("source", "unknown"),
                   "timestamp": raw_data.get("timestamp", time.time()),
                   **metadata
               }
           })
   ```

#### 3.2 è¯­è¨€ç†è§£å±‚(Layer 4)
**ç›®æ ‡**ï¼šè¯­è¨€ç†è§£ä¸æ„å›¾ç”Ÿæˆ

**å®æ–½æ­¥éª¤**ï¼š
1. åˆå¹¶è¯­è¨€ç†è§£åŠŸèƒ½ï¼š
   - `llm_text_processor` â†’ æ ¸å¿ƒLLMå¤„ç†
   - `emotion_judge` â†’ æƒ…æ„Ÿåˆ†æ

2. åˆ›å»ºç»Ÿä¸€æ¥å£ï¼š
   ```python
   # src/understanding/language_understanding.py
   from typing import Protocol, Optional
   from src.canonical.canonical_message import CanonicalMessage
   from src.canonical.intent_object import Intent

   class LanguageUnderstanding(Protocol):
       """è¯­è¨€ç†è§£åè®®"""
       
       async def understand(self, message: CanonicalMessage) -> Intent:
           """ç†è§£æ¶ˆæ¯å¹¶ç”Ÿæˆæ„å›¾"""
           ...
       
       async def get_context(self, max_history: int = 10) -> dict:
           """è·å–ä¸Šä¸‹æ–‡"""
           ...
   ```

3. ç­–ç•¥æ¨¡å¼å®ç°ï¼š
   ```python
   # src/understanding/strategies/openai_llm_strategy.py
   from typing import Dict, Any
   from src.core.strategies.base_strategy import BaseStrategy
   from src.canonical.intent_object import Intent, EmotionType

   class OpenAILLMStrategy(BaseStrategy):
       """OpenAI LLMç­–ç•¥"""
       
       async def initialize(self) -> bool:
           try:
               from openai import AsyncOpenAI
               self.client = AsyncOpenAI(
                   api_key=self.config.get("api_key"),
                   base_url=self.config.get("base_url", "https://api.openai.com/v1/")
               )
               self.model = self.config.get("model", "gpt-4")
               self.logger.info(f"OpenAI LLM åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {self.model}")
               return True
           except Exception as e:
               self.logger.error(f"OpenAI LLM åˆå§‹åŒ–å¤±è´¥: {e}")
               return False
       
       async def understand(self, message: CanonicalMessage) -> Intent:
           """ç†è§£æ¶ˆæ¯å¹¶ç”Ÿæˆæ„å›¾"""
           try:
               # æ„å»ºæç¤ºè¯
               prompt = self._build_prompt(message)
               
               # è°ƒç”¨LLM
               response = await self.client.chat.completions.create(
                   model=self.model,
                   messages=[
                       {"role": "system", "content": self.config.get("system_prompt", "")},
                       {"role": "user", "content": prompt}
                   ],
                   temperature=self.config.get("temperature", 0.7)
               )
               
               response_text = response.choices[0].message.content
               
               # åˆ›å»ºæ„å›¾å¯¹è±¡
               intent = Intent()
               intent.original_text = message.text
               intent.response_text = response_text
               intent.emotion = self._analyze_emotion(response_text)
               intent.metadata = {
                   "model": self.model,
                   "tokens_used": response.usage.total_tokens
               }
               
               return intent
           
           except Exception as e:
               self.logger.error(f"LLMç†è§£å¤±è´¥: {e}")
               # è¿”å›é»˜è®¤æ„å›¾
               intent = Intent()
               intent.original_text = message.text
               intent.response_text = "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç†è§£ã€‚"
               intent.emotion = EmotionType.NEUTRAL
               return intent
       
       def _build_prompt(self, message: CanonicalMessage) -> str:
           """æ„å»ºæç¤ºè¯"""
           prompt_parts = []
           
           # æ·»åŠ ä¸Šä¸‹æ–‡
           if message.context:
               for hist_msg in message.context.history[-5:]:
                   prompt_parts.append(f"{hist_msg.get('role', 'user')}: {hist_msg.get('text', '')}")
           
           # æ·»åŠ å½“å‰æ¶ˆæ¯
           prompt_parts.append(f"ç”¨æˆ·: {message.text}")
           
           return "\n".join(prompt_parts)
       
       def _analyze_emotion(self, text: str) -> EmotionType:
           """åˆ†ææƒ…æ„Ÿï¼ˆç®€å•ç‰ˆæœ¬ï¼‰"""
           # è¿™é‡Œå¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„æƒ…æ„Ÿåˆ†æ
           positive_words = ["å¼€å¿ƒ", "å“ˆå“ˆ", "æ£’", "å–œæ¬¢"]
           negative_words = ["éš¾è¿‡", "ä¼¤å¿ƒ", "ä¸å–œæ¬¢", "è®¨åŒ"]
           
           if any(word in text for word in positive_words):
               return EmotionType.HAPPY
           elif any(word in text for word in negative_words):
               return EmotionType.SAD
           
           return EmotionType.NEUTRAL
   ```

### Phase 4: Layer 5-6 å®ç°

#### 4.1 è¡¨ç°ç”Ÿæˆå±‚(Layer 5)
**ç›®æ ‡**ï¼šç”ŸæˆæŠ½è±¡è¡¨ç°å‚æ•°

**å®æ–½æ­¥éª¤**ï¼š
1. **ç»Ÿä¸€TTSæ¨¡å—**ï¼ˆé‡è¦ï¼‰ï¼š
   ```python
   # src/expression/tts_module.py
   from typing import Optional, Dict, Any, List
   from src.core.strategies.base_strategy import BaseStrategy
   from src.core.factories.tts_factory import TTSFactory

   class UnifiedTTSModule:
       """ç»Ÿä¸€TTSæ¨¡å—ï¼Œæ›¿ä»£åŸæ¥çš„3ä¸ªTTSæ’ä»¶"""
       
       def __init__(self, config: Dict[str, Any]):
           self.factory = TTSFactory()
           self.default_provider = config.get("default_provider", "edge")
           self.provider_configs = config.get("providers", {})
           
           # å½“å‰æ´»è·ƒçš„TTSç­–ç•¥
           self.current_tts_strategy: Optional[BaseStrategy] = None
           
           self.logger = self._get_logger()
       
       async def initialize(self):
           """åˆå§‹åŒ–é»˜è®¤TTSç­–ç•¥"""
           config = self.provider_configs.get(self.default_provider, {})
           self.current_tts_strategy = self.factory.create_strategy(self.default_provider, config)
           
           if await self.current_tts_strategy.initialize():
               self.logger.info(f"TTSç­–ç•¥åˆå§‹åŒ–æˆåŠŸ: {self.default_provider}")
           else:
               self.logger.error(f"TTSç­–ç•¥åˆå§‹åŒ–å¤±è´¥: {self.default_provider}")
       
       async def synthesize(self, text: str) -> bytes:
           """åˆæˆè¯­éŸ³"""
           if not self.current_tts_strategy:
               raise RuntimeError("æ²¡æœ‰å¯ç”¨çš„TTSç­–ç•¥")
           
           return await self.current_tts_strategy.synthesize_speech(text)
       
       async def switch_provider(self, new_provider: str):
           """åŠ¨æ€åˆ‡æ¢TTSæä¾›å•†"""
           if new_provider not in self.provider_configs:
               self.logger.error(f"æœªçŸ¥çš„TTSæä¾›å•†: {new_provider}")
               return False
           
           if new_provider == self.default_provider:
               self.logger.info("å·²ç»æ˜¯å½“å‰æä¾›å•†ï¼Œæ— éœ€åˆ‡æ¢")
               return True
           
           # åˆ‡æ¢ç­–ç•¥
           config = self.provider_configs.get(new_provider, {})
           new_strategy = self.factory.create_strategy(new_provider, config)
           
           if await new_strategy.initialize():
               # æ¸…ç†æ—§ç­–ç•¥
               if self.current_tts_strategy:
                   await self.current_tts_strategy.cleanup()
               
               self.current_tts_strategy = new_strategy
               self.default_provider = new_provider
               
               # å‘é€åˆ‡æ¢äº‹ä»¶
               if hasattr(self, "event_bus"):
                   await self.event_bus.emit("tts.provider_switched", {
                       "old_provider": self.default_provider,
                       "new_provider": new_provider
                   })
               
               return True
           else:
               self.logger.error(f"åˆ‡æ¢TTSæä¾›å•†å¤±è´¥: {new_provider}")
               return False
       
       def get_available_providers(self) -> List[Dict[str, Any]]:
           """è·å–å¯ç”¨æä¾›å•†åˆ—è¡¨"""
           providers = []
           for provider_name in self.factory.get_available_strategies():
               providers.append({
                   "name": provider_name,
                   "description": f"TTS Provider: {provider_name}",
                   "is_current": provider_name == self.default_provider
               })
           return providers
       
       async def cleanup(self):
           """æ¸…ç†èµ„æº"""
           if self.current_tts_strategy:
               await self.current_tts_strategy.cleanup()
   ```

2. åˆ›å»ºè¡¨ç°å‚æ•°å¯¹è±¡ï¼š
   ```python
   # src/expression/render_parameters.py
   from typing import TypedDict, Optional
   from dataclasses import dataclass

   @dataclass
   class ExpressionParameters(TypedDict):
       """è¡¨æƒ…å‚æ•°"""
       expression_name: str
       value: float

   @dataclass
   class AudioParameters(TypedDict):
       """éŸ³é¢‘å‚æ•°"""
       text: str
       voice: Optional[str]
       sample_rate: int

   @dataclass
   class VisualParameters(TypedDict):
       """è§†è§‰å‚æ•°"""
       subtitle_text: Optional[str]
       subtitle_duration: Optional[float]
       show_duration: float

   @dataclass
   class RenderParameters:
       """æ¸²æŸ“å‚æ•°"""
       
       def __init__(self):
           # è¡¨æƒ…å‚æ•°
           self.expressions: dict[str, float] = {}  # {"MouthSmile": 1.0}
           
           # éŸ³é¢‘å‚æ•°
           self.tts_text: Optional[str] = None
           self.tts_voice: Optional[str] = None
           
           # è§†è§‰å‚æ•°
           self.subtitle_text: Optional[str] = None
           self.subtitle_duration: Optional[float] = None
           
           # çƒ­é”®è§¦å‘
           self.hotkeys: List[str] = []
       
       def to_dict(self) -> dict:
           """è½¬æ¢ä¸ºå­—å…¸"""
           return {
               "expressions": self.expressions,
               "tts_text": self.tts_text,
               "tts_voice": self.tts_voice,
               "subtitle_text": self.subtitle_text,
               "subtitle_duration": self.subtitle_duration,
               "hotkeys": self.hotkeys
           }
   ```

3. æ•´åˆå…¶ä»–è¡¨ç°åŠŸèƒ½ï¼š
   ```python
   # src/expression/expression_generator.py
   from typing import Dict, Any
   from src.canonical.intent_object import Intent, EmotionType
   from src.expression.render_parameters import RenderParameters

   class ExpressionGenerator:
       """è¡¨ç°ç”Ÿæˆå™¨"""
       
       def __init__(self, config: Dict[str, Any]):
           self.emotion_map = config.get("emotion_map", {})
           self.tts_enabled = config.get("tts_enabled", True)
           self.subtitle_enabled = config.get("subtitle_enabled", True)
           self.logger = self._get_logger()
       
       async def generate(self, intent: Intent) -> RenderParameters:
           """ä»æ„å›¾ç”Ÿæˆæ¸²æŸ“å‚æ•°"""
           params = RenderParameters()
           
           # ç”Ÿæˆè¡¨æƒ…å‚æ•°
           params.expressions = self._map_emotion_to_expressions(intent.emotion)
           
           # TTSå‚æ•°
           if self.tts_enabled:
               params.tts_text = intent.response_text
           
           # å­—å¹•å‚æ•°
           if self.subtitle_enabled:
               params.subtitle_text = intent.response_text
           
           # çƒ­é”®
           params.hotkeys = self._map_emotion_to_hotkeys(intent.emotion)
           
           return params
       
       def _map_emotion_to_expressions(self, emotion: EmotionType) -> Dict[str, float]:
           """æ˜ å°„æƒ…æ„Ÿåˆ°è¡¨æƒ…å‚æ•°"""
           return self.emotion_map.get(emotion.value, {})
       
       def _map_emotion_to_hotkeys(self, emotion: EmotionType) -> List[str]:
           """æ˜ å°„æƒ…æ„Ÿåˆ°çƒ­é”®"""
           hotkey_map = {
               EmotionType.HAPPY: ["HappyHotkey"],
               EmotionType.SAD: ["SadHotkey"],
               EmotionType.ANGRY: ["AngryHotkey"],
               EmotionType.SURPRISED: ["SurprisedHotkey"]
           }
           return hotkey_map.get(emotion, [])
   ```

#### 4.2 æ¸²æŸ“å‘ˆç°å±‚(Layer 6)
**ç›®æ ‡**ï¼šå®é™…æ¸²æŸ“è¾“å‡º

**å®æ–½æ­¥éª¤**ï¼š
1. ç»Ÿä¸€æ¸²æŸ“å™¨æ¥å£ï¼š
   ```python
   # src/rendering/base_renderer.py
   from typing import Protocol
   from src.expression.render_parameters import RenderParameters

   class Renderer(Protocol):
       """æ¸²æŸ“å™¨åè®®"""
       
       async def render(self, parameters: RenderParameters):
           """æ¸²æŸ“è¾“å‡º"""
           ...
       
       async def cleanup(self):
           """æ¸…ç†èµ„æº"""
           ...
   ```

2. å®ç°å…·ä½“æ¸²æŸ“å™¨ï¼š
   ```python
   # src/rendering/virtual_rendering/vts_renderer.py
   from typing import Dict, Any
   from src.core.strategies.base_strategy import BaseStrategy
   from src.expression.render_parameters import RenderParameters

   class VTSRenderer(BaseStrategy):
       """VTSæ¸²æŸ“å™¨"""
       
       async def initialize(self) -> bool:
           try:
               from vtube_studio import VTuberStudio
               self.vts_client = VTuberStudio()
               await self.vts_client.connect()
               self.logger.info("VTSæ¸²æŸ“å™¨åˆå§‹åŒ–æˆåŠŸ")
               return True
           except Exception as e:
               self.logger.error(f"VTSæ¸²æŸ“å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
               return False
       
       async def render(self, parameters: RenderParameters):
           """æ¸²æŸ“åˆ°VTS"""
           # è®¾ç½®è¡¨æƒ…å‚æ•°
           for exp_name, value in parameters.expressions.items():
               await self.vts_client.set_parameter(exp_name, value)
           
           # è§¦å‘çƒ­é”®
           for hotkey in parameters.hotkeys:
               await self.vts_client.trigger_hotkey(hotkey)
           
           # åŒæ­¥å£å‹ï¼ˆå¦‚æœæœ‰TTSï¼‰
           if parameters.tts_text and hasattr(self, "audio_duration"):
               await self.vts_client.set_parameter("MouthOpen", self.audio_duration)
       
       async def cleanup(self):
           """æ¸…ç†VTSè¿æ¥"""
           if hasattr(self, "vts_client"):
               await self.vts_client.disconnect()
   ```

### Phase 5: Layer 7 å®ç°

#### 5.1 å¤–éƒ¨é›†æˆå±‚
**ç›®æ ‡**ï¼šä¿ç•™æ’ä»¶ç³»ç»Ÿç”¨äºçœŸæ­£æ‰©å±•

**ä¿ç•™æ’ä»¶**ï¼š
- æ¸¸æˆé›†æˆï¼šmainosaba, arknights, minecraft, maicraft
- å·¥å…·é›†æˆï¼šscreen_monitor, remote_stream, read_pingmu
- ç¡¬ä»¶é›†æˆï¼šdg_lab_service

**è¿ç§»åˆ°æ–°ä½ç½®**ï¼š
```
src/integration/game_integration/
src/integration/tools/
src/integration/hardware/
```

### Phase 6: äº‹ä»¶ç³»ç»Ÿé‡æ„

#### 6.1 å®šä¹‰æ ¸å¿ƒäº‹ä»¶æµ
```python
# src/core/event_types.py
from typing import TypedDict, Protocol, Any

class EventData(TypedDict):
    """äº‹ä»¶æ•°æ®åŸºç±»"""
    event: str
    timestamp: float
    source: str
    data: Any

class EventHandler(Protocol):
    """äº‹ä»¶å¤„ç†å™¨åè®®"""
    
    async def __call__(self, event_data: EventData):
        """å¤„ç†äº‹ä»¶"""
        ...

# æ ¸å¿ƒæ•°æ®æµäº‹ä»¶
EVENT_DEFINITIONS = {
    # Layer 1 â†’ Layer 2
    "perception.raw_data": Any,              # RawData
    
    # Layer 2 â†’ Layer 3  
    "normalization.text_ready": str,            # Text
    
    # Layer 3 â†’ Layer 4
    "canonical.message_created": "CanonicalMessage",  # CanonicalMessage
    
    # Layer 4 â†’ Layer 5 â­ æ ¸å¿ƒäº‹ä»¶
    "understanding.intent_generated": "Intent",       # Intent
    
    # Layer 5 â†’ Layer 6 â­ æ ¸å¿ƒäº‹ä»¶
    "expression.parameters_generated": "RenderParameters",  # RenderParameters
    
    # Layer 6 è¾“å‡º
    "rendering.audio_played": dict,
    "rendering.expression_applied": dict,
    "rendering.subtitle_shown": dict,
}
```

#### 6.2 è¿ç§»æœåŠ¡æ³¨å†Œåˆ°EventBus
**é‡ç‚¹è¿ç§»**ï¼š
| åŸæœåŠ¡æ³¨å†Œ | æ–°äº‹ä»¶è®¢é˜…/å‘å¸ƒ |
|------------|-----------------|
| `get_service("vts_control")` | è®¢é˜… `"expression.parameters_generated"` äº‹ä»¶ |
| `get_service("subtitle_service")` | å‘å¸ƒ `"rendering.subtitle_shown"` äº‹ä»¶ |
| `get_service("text_cleanup")` | è®¢é˜… `"normalization.text_ready"` äº‹ä»¶ |
| `get_service("tts_service")` | è®¢é˜… `"expression.parameters_generated"` äº‹ä»¶ |

### Phase 7: é…ç½®ç³»ç»Ÿé‡æ„

#### 7.1 ç®€åŒ–é…ç½®ç»“æ„
```toml
# æ–°é…ç½®æ ¼å¼
[perception]
text_input_provider = "bilibili"
audio_input_enabled = true

[perception.text_inputs.bilibili]
room_id = 123456

[perception.text_inputs.mock]
enabled = true
messages_per_minute = 5

[understanding]
llm_provider = "openai"
model = "gpt-4"

[expression.tts]
default_provider = "edge"

[expression.tts.providers.edge]
voice = "zh-CN-XiaoxiaoNeural"

[expression.tts.providers.gptsovits]
host = "127.0.0.1"
port = 9880

[rendering]
virtual_renderer = "vts"
audio_renderer = "edge_tts"
subtitle_enabled = true
```

#### 7.2 é…ç½®è¿ç§»å·¥å…·
```python
# src/utils/config_migrator.py
from typing import Dict, Any

class ConfigMigrator:
    """é…ç½®è¿ç§»å™¨"""
    
    def __init__(self):
        self.logger = self._get_logger()
    
    def migrate_to_new_format(self, old_config: Dict[str, Any]) -> Dict[str, Any]:
        """è‡ªåŠ¨è¿ç§»æ—§é…ç½®åˆ°æ–°æ ¼å¼"""
        migrated = {}
        
        # è¿ç§»æ’ä»¶é…ç½®
        plugins_section = old_config.get("plugins", {})
        
        # å¤„ç†TTSæ’ä»¶è¿ç§»
        if "tts" in plugins_section or "gptsovits_tts" in plugins_section:
            migrated["expression"] = self._migrate_tts_config(old_config)
        
        # å¤„ç†è¾“å…¥æ’ä»¶è¿ç§»
        if any(key in plugins_section for key in ["console_input", "bili_danmaku"]):
            migrated["perception"] = self._migrate_input_config(old_config)
        
        # å¤„ç†è§£ææ’ä»¶è¿ç§»
        if "llm_text_processor" in plugins_section:
            migrated["understanding"] = self._migrate_llm_config(old_config)
        
        return migrated
    
    def _migrate_tts_config(self, old_config: Dict[str, Any]) -> Dict[str, Any]:
        """è¿ç§»TTSé…ç½®"""
        return {
            "tts": {
                "default_provider": "edge",
                "providers": {
                    "edge": old_config.get("plugins", {}).get("tts", {}),
                    "gptsovits": old_config.get("plugins", {}).get("gptsovits_tts", {}),
                    "omni": old_config.get("plugins", {}).get("omni_tts", {})
                }
            }
        }
    
    def _migrate_input_config(self, old_config: Dict[str, Any]) -> Dict[str, Any]:
        """è¿ç§»è¾“å…¥é…ç½®"""
        return {
            "text_input_provider": "bilibili",
            "text_inputs": {
                "bilibili": old_config.get("plugins", {}).get("bili_danmaku", {}),
                "mock": old_config.get("plugins", {}).get("mock_danmaku", {})
            }
        }
    
    def _migrate_llm_config(self, old_config: Dict[str, Any]) -> Dict[str, Any]:
        """è¿ç§»LLMé…ç½®"""
        return {
            "llm_provider": "openai",
            "model": "gpt-4"
        }
```

## ğŸ”„ å®æ–½æ­¥éª¤è¯¦ç»†æŒ‡å—

### æ¯ä¸ªLayerçš„æ ‡å‡†å®æ–½æ­¥éª¤

#### Step 1: å®šä¹‰æ¥å£
```python
# åˆ›å»ºæŠ½è±¡åŸºç±»ï¼Œå®šä¹‰ç»Ÿä¸€æ¥å£
from typing import Protocol, runtime_checkable

@runtime_checkable
class BaseLayer(Protocol):
    """å±‚çº§åè®®"""
    
    async def process(self, input_data: Any) -> Any:
        """å¤„ç†æ•°æ®"""
        ...
```

#### Step 2: å®ç°ç­–ç•¥
```python
# ä¸ºæ¯ä¸ªå®ç°åˆ›å»ºç­–ç•¥ç±»
class ConcreteStrategy(BaseStrategy):
    def __init__(self, config: Dict[str, Any]):
        self.config = config
    
    async def process(self, input_data: Any) -> Any:
        # å…·ä½“å®ç°
        pass
```

#### Step 3: åˆ›å»ºå·¥å‚
```python
# åˆ›å»ºå·¥å‚ç±»æ”¯æŒåŠ¨æ€é€‰æ‹©
class LayerFactory(StrategyFactory):
    def __init__(self):
        self._strategies = {
            "implementation1": ConcreteStrategy1,
            "implementation2": ConcreteStrategy2,
        }
    
    def create(self, provider: str, config: Dict[str, Any]) -> BaseStrategy:
        strategy_class = self._strategies.get(provider)
        if not strategy_class:
            raise ValueError(f"Unknown provider: {provider}")
        return strategy_class(config)
```

#### Step 4: é›†æˆäº‹ä»¶ç³»ç»Ÿ
```python
# åœ¨Layerä¸­ä½¿ç”¨EventBus
class LayerModule:
    def __init__(self, event_bus, config: Dict[str, Any]):
        self.event_bus = event_bus
        self.factory = LayerFactory()
        
        # è®¢é˜…è¾“å…¥äº‹ä»¶
        self.event_bus.on(self.input_event, self.on_input)
        
        # å‘å¸ƒè¾“å‡ºäº‹ä»¶
        self.output_event = self.output_event_name
    
    async def on_input(self, event_data: EventData):
        # å¤„ç†è¾“å…¥
        result = await self.process(event_data.data)
        
        # å‘å¸ƒè¾“å‡º
        await self.event_bus.emit(self.output_event, {
            "timestamp": time.time(),
            "source": self.__class__.__name__,
            "data": result
        })
```

### å…³é”®å®æ–½è¦ç‚¹

#### 1. äº‹ä»¶å‘½åè§„èŒƒ
```python
# äº‹ä»¶å‘½åï¼š{layer}.{action}.{status}
"perception.raw_data"
"normalization.text_ready"  
"understanding.intent_generated"
"expression.parameters_generated"
"rendering.audio_played"
```

#### 2. é”™è¯¯å¤„ç†ç­–ç•¥
```python
# æ¯ä¸ªLayerçš„é”™è¯¯å¤„ç†
class LayerModule:
    async def process_with_error_handling(self, data):
        try:
            result = await self.process(data)
            await self.event_bus.emit(self.success_event, result)
        except Exception as e:
            self.logger.error(f"Layerå¤„ç†å¤±è´¥: {e}")
            await self.event_bus.emit(self.error_event, {
                "error": str(e),
                "timestamp": time.time()
            })
```

#### 3. é…ç½®çƒ­é‡è½½
```python
# æ”¯æŒè¿è¡Œæ—¶é…ç½®æ›´æ–°
class LayerModule:
    async def reload_config(self, new_config: Dict[str, Any]):
        self.config = new_config
        # é‡æ–°åˆå§‹åŒ–ç­–ç•¥
        await self.strategy.cleanup()
        self.strategy = self.factory.create(
            self.config.get("provider"), 
            self.config
        )
        await self.strategy.initialize()
```

## âœ… éªŒè¯æ ‡å‡†

### æ¯ä¸ªLayerå®Œæˆæ ‡å‡†
- [ ] æ¥å£å®šä¹‰å®Œæˆï¼Œæ‰€æœ‰å¿…éœ€æ–¹æ³•éƒ½æœ‰æ–‡æ¡£
- [ ] è‡³å°‘ä¸€ä¸ªå…·ä½“å®ç°å¯ä»¥å·¥ä½œ
- [ ] å·¥å‚æ¨¡å¼å¯ä»¥åŠ¨æ€é€‰æ‹©å®ç°
- [ ] äº‹ä»¶è®¢é˜…/å‘å¸ƒæ­£å¸¸å·¥ä½œ
- [ ] é…ç½®å¯ä»¥æ­£ç¡®åŠ è½½å’Œä½¿ç”¨

### æ•´ä½“éªŒè¯æ ‡å‡†
- [ ] æ‰€æœ‰ç°æœ‰åŠŸèƒ½éƒ½å¯ä»¥æ­£å¸¸å·¥ä½œ
- [ ] é…ç½®ç®€åŒ–åå¯ä»¥æ­£å¸¸å¯åŠ¨
- [ ] äº‹ä»¶ç³»ç»Ÿæ›¿ä»£äº†æ‰€æœ‰æœåŠ¡æ³¨å†Œ
- [ ] ç­–ç•¥æ¨¡å¼æ”¯æŒè¿è¡Œæ—¶åˆ‡æ¢
- [ ] æ— å¾ªç¯ä¾èµ–ï¼Œå¯åŠ¨é¡ºåºæ— å…³

## ğŸš€ å¿«é€Ÿå¼€å§‹æ£€æŸ¥æ¸…å•

### å®æ–½å‰å‡†å¤‡
- [ ] å¤‡ä»½ç°æœ‰ä»£ç 
- [ ] ç¡®è®¤ç†è§£äº†æ‰€æœ‰ç°æœ‰åŠŸèƒ½
- [ ] å‡†å¤‡äº†æµ‹è¯•æ•°æ®

### å®æ–½ä¸­æ£€æŸ¥
- [ ] æ¯å®Œæˆä¸€ä¸ªLayerå°±è¿›è¡ŒåŠŸèƒ½æµ‹è¯•
- [ ] ç¡®ä¿äº‹ä»¶æ­£ç¡®è®¢é˜…å’Œå‘å¸ƒ
- [ ] éªŒè¯é…ç½®æ ¼å¼æ­£ç¡®

### å®æ–½åéªŒè¯
- [ ] æ‰€æœ‰åŸæœ‰åŠŸèƒ½æ­£å¸¸å·¥ä½œ
- [ ] æ–°æ¶æ„å¯ä»¥æ­£å¸¸å¯åŠ¨
- [ ] æ€§èƒ½æ²¡æœ‰æ˜æ˜¾ä¸‹é™
- [ ] æ—¥å¿—è¾“å‡ºæ¸…æ™°å¯è°ƒè¯•

## ğŸ“ æ³¨æ„äº‹é¡¹

### å¼€å‘åŸåˆ™
1. **å…ˆæ¥å£ï¼Œåå®ç°**ï¼šå…ˆå®šä¹‰æ¸…æ™°çš„æ¥å£ï¼Œå†å†™å…·ä½“å®ç°
2. **äº‹ä»¶ä¼˜å…ˆ**ï¼šä¼˜å…ˆä½¿ç”¨EventBusï¼Œé¿å…ç›´æ¥ä¾èµ–
3. **ç­–ç•¥è§£è€¦**ï¼šç”¨ç­–ç•¥æ¨¡å¼éš”ç¦»ä¸åŒå®ç°
4. **å·¥å‚é€‰æ‹©**ï¼šç”¨å·¥å‚æ¨¡å¼æ”¯æŒåŠ¨æ€åˆ‡æ¢
5. **é…ç½®ç®€åŒ–**ï¼šå‡å°‘é…ç½®å¤æ‚åº¦ï¼Œæé«˜å¯ç»´æŠ¤æ€§

### é£é™©æ§åˆ¶
1. **åˆ†æ­¥å®æ–½**ï¼šæŒ‰Layeré¡ºåºï¼Œæ¯æ­¥éªŒè¯
2. **åŠŸèƒ½ä¿æŒ**ï¼šç¡®ä¿é‡æ„è¿‡ç¨‹ä¸­åŠŸèƒ½ä¸ä¸¢å¤±
3. **é”™è¯¯éš”ç¦»**ï¼šæ¯å±‚ç‹¬ç«‹é”™è¯¯å¤„ç†ï¼Œä¸å½±å“å…¶ä»–å±‚
4. **é…ç½®å…¼å®¹**ï¼šæä¾›é…ç½®è¿ç§»å·¥å…·
5. **æ—¥å¿—å®Œå–„**ï¼šè¯¦ç»†æ—¥å¿—ä¾¿äºé—®é¢˜å®šä½

## ğŸ¯ é¢„æœŸæˆæœ

### æ¶æ„æ”¶ç›Š
- **ä¾èµ–åœ°ç‹±æ¶ˆé™¤**ï¼šEventBuså®Œå…¨æ›¿ä»£æœåŠ¡æ³¨å†Œ
- **ä»£ç é‡å¤å‡å°‘**ï¼šç»Ÿä¸€æ¥å£æ›¿ä»£é‡å¤æ’ä»¶
- **é…ç½®ç®€åŒ–**ï¼šé…ç½®è¡Œæ•°å‡å°‘40%ä»¥ä¸Š
- **æ‰©å±•æ€§æå‡**ï¼šæ–°å¢å®ç°åªéœ€å®ç°ç­–ç•¥æ¥å£

### å¼€å‘ä½“éªŒæå‡
- **å¯åŠ¨é¡ºåºæ— å…³**ï¼šæ— ä¾èµ–é“¾ï¼Œä»»æ„å¯åŠ¨é¡ºåº
- **çƒ­åˆ‡æ¢æ”¯æŒ**ï¼šè¿è¡Œæ—¶åŠ¨æ€åˆ‡æ¢å®ç°
- **è°ƒè¯•å‹å¥½**ï¼šæ¸…æ™°çš„äº‹ä»¶æµï¼Œæ˜“äºå®šä½é—®é¢˜
- **æ–‡æ¡£å®Œå–„**ï¼šæ¯å±‚èŒè´£æ¸…æ™°ï¼Œæ˜“äºç†è§£

è¿™ä¸ªå®æ–½è®¡åˆ’æä¾›äº†è¯¦ç»†çš„åˆ†æ­¥é‡æ„æŒ‡å—ï¼Œç¡®ä¿åœ¨1-2å¤©å†…å®Œæˆå…¨é¢é‡æ„ï¼ŒåŒæ—¶ä¿æŒåŠŸèƒ½å®Œæ•´æ€§å’Œæ¶æ„æ¸…æ™°æ€§ã€‚