# DataCacheè®¾è®¡

## ğŸ¯ æ ¸å¿ƒç›®æ ‡

ä¸ºLayer 2ï¼ˆè¾“å…¥æ ‡å‡†åŒ–å±‚ï¼‰æä¾›åŸå§‹æ•°æ®ç¼“å­˜æœåŠ¡ï¼Œæ”¯æŒå…ƒæ•°æ®ä¼ é€’å’Œç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼Œé¿å…EventBusä¼ é€’å¤§å¯¹è±¡ã€‚

---

## ğŸ“Š è®¾è®¡æ¦‚è§ˆ

### 1. è®¾è®¡èƒŒæ™¯

**é—®é¢˜**ï¼š
- Layer 2ç»Ÿä¸€è½¬Textï¼Œä½†æŸäº›åœºæ™¯ï¼ˆå¦‚å›¾åƒè¾“å…¥ï¼‰éœ€è¦ä¿ç•™åŸå§‹æ•°æ®
- EventBusä¼ é€’åŸå§‹å¤§å¯¹è±¡ï¼ˆå›¾åƒã€éŸ³é¢‘ï¼‰ä¼šå½±å“æ€§èƒ½
- éœ€è¦æŒ‰éœ€åŠ è½½ï¼Œé¿å…å†…å­˜æµªè´¹

**è§£å†³æ–¹æ¡ˆ**ï¼š
- NormalizedTextåŒ…å«data_refï¼ˆå¼•ç”¨ï¼‰è€ŒéåŸå§‹æ•°æ®
- åŸå§‹æ•°æ®å­˜å‚¨åœ¨DataCacheä¸­
- é€šè¿‡å¼•ç”¨æŒ‰éœ€åŠ è½½

### 2. è®¾è®¡åŸåˆ™

1. **æ€§èƒ½ä¼˜åŒ–**ï¼šEventBusåªä¼ é€’è½»é‡çº§å¯¹è±¡
2. **ç”Ÿå‘½å‘¨æœŸç®¡ç†**ï¼šè‡ªåŠ¨è¿‡æœŸï¼Œé¿å…å†…å­˜æ³„æ¼
3. **æŒ‰éœ€åŠ è½½**ï¼šåªåœ¨éœ€è¦æ—¶ä»ç¼“å­˜è·å–
4. **æ˜“äºæµ‹è¯•**ï¼šæ¥å£å¯mock

---

## ğŸ—ï¸ æ¥å£è®¾è®¡

### DataCacheæ¥å£

```python
from typing import Optional, Any, Dict, List
from dataclasses import dataclass
from enum import Enum
import time

class CacheEvictionPolicy(str, Enum):
    """ç¼“å­˜æ·˜æ±°ç­–ç•¥"""
    TTL_ONLY = "ttl_only"          # ä»…æŒ‰TTLæ·˜æ±°
    LRU_ONLY = "lru_only"          # ä»…æŒ‰LRUæ·˜æ±°
    TTL_OR_LRU = "ttl_or_lru"      # TTLæˆ–LRUä»»ä¸€è§¦å‘
    TTL_AND_LRU = "ttl_and_lru"    # TTLå’ŒLRUéƒ½è§¦å‘

@dataclass
class CacheConfig:
    """ç¼“å­˜é…ç½®"""
    ttl_seconds: int = 300                 # TTLé»˜è®¤5åˆ†é’Ÿ
    max_size_mb: int = 100                # æœ€å¤§100MB
    max_entries: int = 1000                # æœ€å¤š1000ä¸ªæ¡ç›®
    eviction_policy: CacheEvictionPolicy = CacheEvictionPolicy.TTL_OR_LRU

@dataclass
class CacheStats:
    """ç¼“å­˜ç»Ÿè®¡"""
    hits: int = 0              # å‘½ä¸­æ¬¡æ•°
    misses: int = 0            # æœªå‘½ä¸­æ¬¡æ•°
    evictions: int = 0         # æ·˜æ±°æ¬¡æ•°
    current_size_mb: float = 0  # å½“å‰å¤§å°ï¼ˆMBï¼‰
    current_entries: int = 0    # å½“å‰æ¡ç›®æ•°

class NotFoundError(Exception):
    """ç¼“å­˜æ•°æ®æœªæ‰¾åˆ°æˆ–å·²è¿‡æœŸ"""
    pass

class CapacityError(Exception):
    """ç¼“å­˜å·²æ»¡ï¼Œæ— æ³•å­˜å‚¨"""
    pass

class DataCache(Protocol):
    """æ•°æ®ç¼“å­˜æœåŠ¡ï¼ˆç®¡ç†åŸå§‹æ•°æ®çš„ç”Ÿå‘½å‘¨æœŸï¼‰"""

    async def store(
        self,
        data: Any,
        ttl: Optional[int] = None,
        tags: Optional[Dict[str, str]] = None
    ) -> str:
        """
        å­˜å‚¨åŸå§‹æ•°æ®

        Args:
            data: åŸå§‹æ•°æ®ï¼ˆbytes, Image, Audioç­‰ï¼‰
            ttl: ç”Ÿå­˜æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®çš„ttl_seconds
            tags: æ ‡ç­¾ï¼ˆå¯ç”¨äºæŸ¥è¯¢å’Œåˆ†ç±»ï¼‰

        Returns:
            æ•°æ®å¼•ç”¨ï¼ˆå¦‚ "cache://image/abc123"ï¼‰

        Raises:
            CapacityError: ç¼“å­˜å·²æ»¡ï¼Œæ— æ³•å­˜å‚¨
        """
        ...

    async def retrieve(self, data_ref: str) -> Any:
        """
        æ ¹æ®å¼•ç”¨è·å–åŸå§‹æ•°æ®

        Args:
            data_ref: æ•°æ®å¼•ç”¨

        Returns:
            åŸå§‹æ•°æ®

        Raises:
            NotFoundError: æ•°æ®ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ
        """
        ...

    async def delete(self, data_ref: str) -> bool:
        """
        åˆ é™¤æ•°æ®

        Args:
            data_ref: æ•°æ®å¼•ç”¨

        Returns:
            æ˜¯å¦åˆ é™¤æˆåŠŸï¼ˆæ•°æ®å­˜åœ¨ï¼‰
        """
        ...

    async def clear(self):
        """æ¸…ç©ºæ‰€æœ‰ç¼“å­˜"""
        ...

    def get_stats(self) -> CacheStats:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        ...

    async def find_by_tags(self, tags: Dict[str, str]) -> List[str]:
        """
        æ ¹æ®æ ‡ç­¾æŸ¥æ‰¾æ•°æ®å¼•ç”¨

        Args:
            tags: æ ‡ç­¾ï¼ˆå®Œå…¨åŒ¹é…ï¼‰

        Returns:
            æ•°æ®å¼•ç”¨åˆ—è¡¨
        """
        ...
```

### NormalizedTextç»“æ„

```python
from dataclasses import dataclass
from typing import Optional, Any, Dict

@dataclass
class NormalizedText:
    """æ ‡å‡†åŒ–æ–‡æœ¬"""
    text: str                    # æ–‡æœ¬æè¿°
    metadata: Dict[str, Any]      # å…ƒæ•°æ®ï¼ˆå¿…éœ€ï¼‰
    data_ref: Optional[str] = None  # åŸå§‹æ•°æ®å¼•ç”¨ï¼ˆå¯é€‰ï¼‰

    # ç¤ºä¾‹ï¼šå›¾åƒè¾“å…¥
    # NormalizedText(
    #     text="ç”¨æˆ·å‘é€äº†ä¸€å¼ çŒ«å’ªå›¾ç‰‡",
    #     metadata={
    #         "type": "image",
    #         "format": "jpeg",
    #         "size": 102400,
    #         "timestamp": 1234567890
    #     },
    #     data_ref="cache://image/abc123"  # å¼•ç”¨ï¼Œä¸æ˜¯å®é™…æ•°æ®
    # )

    # ç¤ºä¾‹ï¼šæ–‡æœ¬è¾“å…¥ï¼ˆä¸éœ€è¦ä¿ç•™åŸå§‹æ•°æ®ï¼‰
    # NormalizedText(
    #     text="ç”¨æˆ·è¯´ï¼šä½ å¥½",
    #     metadata={
    #         "type": "text",
    #         "source": "danmaku",
    #         "timestamp": 1234567890
    #     },
    #     data_ref=None
    # )
```

---

## ğŸ’¾ å®ç°ç¤ºä¾‹

### MemoryDataCacheå®ç°

```python
import asyncio
import hashlib
from typing import Dict, List, Optional, Any
from collections import OrderedDict

class MemoryDataCache:
    """å†…å­˜å®ç°çš„æ•°æ®ç¼“å­˜"""

    def __init__(self, config: CacheConfig):
        self.config = config
        self._cache: OrderedDict[str, CacheEntry] = OrderedDict()
        self._async_lock = asyncio.Lock()  # åç¨‹é”
        self._thread_lock = threading.Lock()  # çº¿ç¨‹é”ï¼ˆåŒé‡ä¿æŠ¤ï¼‰
        self._stats = CacheStats()

        # å¯åŠ¨åå°æ¸…ç†ä»»åŠ¡
        asyncio.create_task(self._cleanup_loop())

    @dataclass
    class CacheEntry:
        data: Any
        size_bytes: int
        created_at: float
        ttl: int
        tags: Dict[str, str]
        access_count: int = 0
        last_access_at: float = 0

    async def store(
        self,
        data: Any,
        ttl: Optional[int] = None,
        tags: Optional[Dict[str, str]] = None
    ) -> str:
        async with self._lock:
            # 1. æ£€æŸ¥å®¹é‡
            data_size = self._estimate_size(data)
            if not await self._check_capacity(data_size):
                raise CapacityError(f"Cache full, cannot store {data_size} bytes")

            # 2. ç”Ÿæˆå¼•ç”¨
            data_ref = self._generate_ref(data)

            # 3. å­˜å‚¨æ•°æ®
            entry = self.CacheEntry(
                data=data,
                size_bytes=data_size,
                created_at=time.time(),
                ttl=ttl or self.config.ttl_seconds,
                tags=tags or {},
                last_access_at=time.time()
            )

            self._cache[data_ref] = entry
            self._update_stats_on_store(data_size)

            return data_ref

    async def retrieve(self, data_ref: str) -> Any:
        # ä½¿ç”¨asyncioé”ï¼ˆåç¨‹çº§åˆ«ï¼‰
        async with self._async_lock:
            return self._retrieve_sync(data_ref)

    def _retrieve_sync(self, data_ref: str) -> Any:
        # ä½¿ç”¨threadé”ï¼ˆçº¿ç¨‹çº§åˆ«ï¼‰
        with self._thread_lock:
            # 1. æ£€æŸ¥æ˜¯å¦å­˜åœ¨
            entry = self._cache.get(data_ref)
            if entry is None:
                self._stats.misses += 1
                raise NotFoundError(f"Data not found: {data_ref}")

            # 2. æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
            if self._is_expired(entry):
                del self._cache[data_ref]
                self._stats.misses += 1
                raise NotFoundError(f"Data expired: {data_ref}")

            # 3. æ›´æ–°è®¿é—®ä¿¡æ¯ï¼ˆç”¨äºLRUï¼‰
            entry.access_count += 1
            entry.last_access_at = time.time()
            self._cache.move_to_end(data_ref)  # LRU: ç§»åˆ°æœ€å

            self._stats.hits += 1
            return entry.data

    async def delete(self, data_ref: str) -> bool:
        async with self._lock:
            entry = self._cache.pop(data_ref, None)
            if entry:
                self._update_stats_on_delete(entry.size_bytes)
                return True
            return False

    async def clear(self):
        async with self._lock:
            self._cache.clear()
            self._stats = CacheStats()

    def get_stats(self) -> CacheStats:
        async with self._lock:
            self._update_stats_size()
            return CacheStats(
                hits=self._stats.hits,
                misses=self._stats.misses,
                evictions=self._stats.evictions,
                current_size_mb=self._stats.current_size_mb,
                current_entries=len(self._cache)
            )

    async def find_by_tags(self, tags: Dict[str, str]) -> List[str]:
        async with self._lock:
            matches = []
            for ref, entry in self._cache.items():
                if self._is_expired(entry):
                    continue
                if all(entry.tags.get(k) == v for k, v in tags.items()):
                    matches.append(ref)
            return matches

    # ========== ç§æœ‰æ–¹æ³• ==========

    def _generate_ref(self, data: Any) -> str:
        """
        ç”Ÿæˆæ•°æ®å¼•ç”¨

        ç­–ç•¥ï¼š
        - bytes: ç›´æ¥å¯¹æ•°æ®æ±‚hash
        - str: å¯¹utf-8ç¼–ç åæ±‚hash
        - å…¶ä»–ç±»å‹: ä½¿ç”¨UUID + ç±»å‹æ ‡è¯†
        """
        import uuid

        if isinstance(data, bytes):
            hash_input = data
            prefix = "bytes"
        elif isinstance(data, str):
            hash_input = data.encode()
            prefix = "str"
        else:
            # å¯¹äºå…¶ä»–å¯¹è±¡ï¼Œç”ŸæˆéšæœºUUID + ç±»å‹æ ‡è¯†
            type_id = type(data).__name__
            hash_input = f"{type_id}:{uuid.uuid4()}".encode()
            prefix = type_id

        hash_str = hashlib.sha256(hash_input).hexdigest()[:12]
        return f"cache://{prefix}/{hash_str}"

    def _estimate_size(self, data: Any) -> int:
        """ä¼°ç®—æ•°æ®å¤§å°ï¼ˆå­—èŠ‚ï¼‰"""
        if isinstance(data, bytes):
            return len(data)
        elif isinstance(data, str):
            return len(data.encode())
        else:
            # å…¶ä»–ç±»å‹ä¼°ç®—ä¸º1KB
            return 1024

    async def _check_capacity(self, new_size: int) -> bool:
        """æ£€æŸ¥å®¹é‡ï¼Œå¿…è¦æ—¶æ·˜æ±°æ—§æ•°æ®"""
        stats = await self.get_stats()

        # æ£€æŸ¥æ¡ç›®æ•°
        if stats.current_entries >= self.config.max_entries:
            return await self._evict_by_policy()

        # æ£€æŸ¥å¤§å°
        if stats.current_size_mb * 1024 * 1024 + new_size > self.config.max_size_mb * 1024 * 1024:
            return await self._evict_by_policy()

        return True

    async def _evict_by_policy(self) -> bool:
        """æ ¹æ®ç­–ç•¥æ·˜æ±°æ•°æ®"""
        policy = self.config.eviction_policy

        if policy == CacheEvictionPolicy.TTL_ONLY:
            return await self._evict_expired()
        elif policy == CacheEvictionPolicy.LRU_ONLY:
            return await self._evict_lru()
        elif policy == CacheEvictionPolicy.TTL_OR_LRU:
            # å°è¯•å…ˆæ·˜æ±°è¿‡æœŸçš„
            if await self._evict_expired():
                return True
            # å¦‚æœè¿˜ä¸å¤Ÿï¼Œæ·˜æ±°LRU
            return await self._evict_lru()
        elif policy == CacheEvictionPolicy.TTL_AND_LRU:
            # åªæ·˜æ±°æ—¢è¿‡æœŸåˆæ˜¯LRUçš„
            return await self._evict_expired_and_lru()

        return False

    async def _evict_expired(self) -> bool:
        """æ·˜æ±°è¿‡æœŸæ•°æ®"""
        expired_refs = []
        for ref, entry in self._cache.items():
            if self._is_expired(entry):
                expired_refs.append(ref)

        for ref in expired_refs:
            entry = self._cache.pop(ref)
            self._stats.evictions += 1
            self._update_stats_on_delete(entry.size_bytes)

        return len(expired_refs) > 0

    async def _evict_lru(self) -> bool:
        """æ·˜æ±°æœ€ä¹…æœªä½¿ç”¨çš„æ•°æ®ï¼ˆLRUï¼‰"""
        if not self._cache:
            return False

        # OrderedDictçš„ç¬¬ä¸€ä¸ªå…ƒç´ æ˜¯æœ€ä¹…æœªä½¿ç”¨çš„
        ref, entry = self._cache.popitem(last=False)
        self._stats.evictions += 1
        self._update_stats_on_delete(entry.size_bytes)
        return True

    async def _evict_expired_and_lru(self) -> bool:
        """æ·˜æ±°æ—¢è¿‡æœŸåˆæ˜¯æœ€ä¹…æœªä½¿ç”¨çš„æ•°æ®"""
        # æ‰¾åˆ°æ‰€æœ‰è¿‡æœŸæ•°æ®ä¸­æœ€ä¹…æœªä½¿ç”¨çš„
        expired_refs = []
        for ref, entry in self._cache.items():
            if self._is_expired(entry):
                expired_refs.append((ref, entry.last_access_at))

        if not expired_refs:
            return False

        # æŒ‰last_access_atæ’åºï¼Œæ·˜æ±°æœ€ä¹…æœªä½¿ç”¨çš„
        expired_refs.sort(key=lambda x: x[1])
        ref, _ = expired_refs[0]

        entry = self._cache.pop(ref)
        self._stats.evictions += 1
        self._update_stats_on_delete(entry.size_bytes)
        return True

    def _is_expired(self, entry: CacheEntry) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿‡æœŸ"""
        return time.time() - entry.created_at > entry.ttl

    def _update_stats_on_store(self, size_bytes: int):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯ï¼ˆå­˜å‚¨ï¼‰"""
        self._stats.current_entries = len(self._cache)
        self._stats.current_size_mb = sum(e.size_bytes for e in self._cache.values()) / (1024 * 1024)

    def _update_stats_on_delete(self, size_bytes: int):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯ï¼ˆåˆ é™¤ï¼‰"""
        self._stats.current_entries = len(self._cache)
        self._stats.current_size_mb = sum(e.size_bytes for e in self._cache.values()) / (1024 * 1024)

    def _update_stats_size(self):
        """æ›´æ–°ç»Ÿè®¡ä¿¡æ¯å¤§å°"""
        self._stats.current_size_mb = sum(e.size_bytes for e in self._cache.values()) / (1024 * 1024)

    async def _cleanup_loop(self):
        """åå°æ¸…ç†å¾ªç¯"""
        while True:
            try:
                await asyncio.sleep(60)  # æ¯åˆ†é’Ÿæ¸…ç†ä¸€æ¬¡
                await self._evict_expired()
            except Exception as e:
                # è®°å½•é”™è¯¯ï¼Œä¸ä¸­æ–­å¾ªç¯
                print(f"Cache cleanup error: {e}")
```

---

## ğŸ“‹ é…ç½®ç¤ºä¾‹

### DataCacheé…ç½®

```toml
[data_cache]
# TTLé»˜è®¤5åˆ†é’Ÿ
ttl_seconds = 300

# æœ€å¤§100MB
max_size_mb = 100

# æœ€å¤š1000ä¸ªæ¡ç›®
max_entries = 1000

# æ·˜æ±°ç­–ç•¥ï¼šTTLæˆ–LRUä»»ä¸€è§¦å‘
eviction_policy = "ttl_or_lru"  # ttl_only | lru_only | ttl_or_lru | ttl_and_lru
```

---

## ğŸ”„ ä½¿ç”¨ç¤ºä¾‹

### Layer 2ï¼ˆNormalizationï¼‰ä½¿ç”¨DataCache

```python
class Normalizer:
    """è¾“å…¥æ ‡å‡†åŒ–å±‚"""

    def __init__(self, event_bus: EventBus, data_cache: DataCache):
        self.event_bus = event_bus
        self.data_cache = data_cache

    async def normalize(self, raw_data: RawData) -> NormalizedText:
        """æ ‡å‡†åŒ–åŸå§‹æ•°æ®"""

        # 1. è½¬æ¢ä¸ºæ–‡æœ¬
        text = await self._to_text(raw_data.content)

        # 2. å¦‚æœéœ€è¦ä¿ç•™åŸå§‹æ•°æ®ï¼Œæ”¾å…¥ç¼“å­˜
        data_ref = None
        if raw_data.preserve_original:
            data_ref = await self.data_cache.store(
                data=raw_data.original_data,
                ttl=300,  # 5åˆ†é’Ÿ
                tags={
                    "type": raw_data.type,
                    "source": raw_data.source
                }
            )

        # 3. åˆ›å»ºNormalizedText
        normalized = NormalizedText(
            text=text,
            metadata={
                "type": raw_data.type,
                "source": raw_data.source,
                "timestamp": raw_data.timestamp
            },
            data_ref=data_ref
        )

        # 4. å‘å¸ƒäº‹ä»¶ï¼ˆåªä¼ é€’NormalizedTextï¼Œä¸ä¼ é€’åŸå§‹æ•°æ®ï¼‰
        await self.event_bus.emit("normalization.text.ready", {
            "normalized": normalized
        })

        return normalized
```

### Layer 5ï¼ˆUnderstandingï¼‰ä½¿ç”¨DataCache

```python
class Understanding:
    """è¡¨ç°ç†è§£å±‚"""

    def __init__(self, event_bus: EventBus, data_cache: DataCache):
        self.event_bus = event_bus
        self.data_cache = data_cache

    async def on_text_ready(self, event: dict):
        """å¤„ç†æ–‡æœ¬å°±ç»ªäº‹ä»¶"""
        normalized: NormalizedText = event.get("normalized")

        # 1. å¤„ç†æ–‡æœ¬
        text = normalized.text
        metadata = normalized.metadata

        # 2. å¦‚æœéœ€è¦è®¿é—®åŸå§‹æ•°æ®ï¼Œé€šè¿‡å¼•ç”¨è·å–
        image_features = None
        if normalized.data_ref:
            try:
                original_data = await self.data_cache.retrieve(normalized.data_ref)
                # ä½¿ç”¨åŸå§‹æ•°æ®è¿›è¡Œå¤šæ¨¡æ€å¤„ç†
                image_features = await self._extract_image_features(original_data)
            except NotFoundError:
                # æ•°æ®å·²è¿‡æœŸï¼Œä½¿ç”¨æ–‡æœ¬å¤„ç†
                self.logger.warning(f"Original data expired: {normalized.data_ref}")
                image_features = None

        # 3. ç”ŸæˆIntent
        intent = await self._generate_intent(text, metadata, image_features)

        # 4. å‘å¸ƒäº‹ä»¶
        await self.event_bus.emit("understanding.intent.ready", {
            "intent": intent
        })

    async def _extract_image_features(self, image_data: Any):
        """æå–å›¾åƒç‰¹å¾"""
        # å®ç°å¤šæ¨¡æ€å¤„ç†é€»è¾‘
        pass
```

---

## âœ… å…³é”®ä¼˜åŠ¿

### 1. æ€§èƒ½ä¼˜åŒ–
- âœ… EventBusåªä¼ é€’è½»é‡çº§çš„NormalizedTextå¯¹è±¡
- âœ… åŸå§‹æ•°æ®å­˜å‚¨åœ¨DataCacheä¸­ï¼Œä¸å ç”¨EventBuså¸¦å®½
- âœ… æŒ‰éœ€åŠ è½½ï¼Œåªæœ‰éœ€è¦æ—¶æ‰ä»ç¼“å­˜ä¸­è·å–

### 2. ç”Ÿå‘½å‘¨æœŸç®¡ç†
- âœ… DataCacheè‡ªåŠ¨ç®¡ç†åŸå§‹æ•°æ®çš„ç”Ÿå‘½å‘¨æœŸï¼ˆTTLè¿‡æœŸè‡ªåŠ¨åˆ é™¤ï¼‰
- âœ… é¿å…å†…å­˜æ³„æ¼
- âœ… å¯é…ç½®çš„TTLï¼Œé€‚åº”ä¸åŒåœºæ™¯

### 3. çµæ´»æ€§
- âœ… ä¸éœ€è¦ä¿ç•™åŸå§‹æ•°æ®æ—¶ï¼Œdata_ref=Noneï¼Œä¸å ç”¨ç¼“å­˜
- âœ… éœ€è¦ä¿ç•™æ—¶ï¼Œé€šè¿‡data_refæŒ‰éœ€åŠ è½½
- âœ… æ”¯æŒå¤šç§æ•°æ®ç±»å‹ï¼ˆbytes, Image, Audioç­‰ï¼‰
- âœ… æ”¯æŒæ ‡ç­¾æŸ¥è¯¢ï¼Œä¾¿äºæ‰¹é‡æŸ¥æ‰¾

### 4. å¯æµ‹è¯•æ€§
- âœ… DataCacheå¯ä»¥mockï¼Œæ˜“äºå•å…ƒæµ‹è¯•
- âœ… NormalizedTextæ˜¯çº¯æ•°æ®ç»“æ„ï¼Œæ˜“äºéªŒè¯

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [7å±‚æ¶æ„è®¾è®¡](./layer_refactoring.md)
- [å¤šProviderå¹¶å‘è®¾è®¡](./multi_provider.md)
- [æ’ä»¶ç³»ç»Ÿè®¾è®¡](./plugin_system.md)
