# ScreenReader - å±å¹•å†…å®¹é˜…è¯»å™¨
# 
# ä¾èµ–:
# - pip install openai  (OpenAI å…¼å®¹ API å®¢æˆ·ç«¯)
# - pip install pillow  (å›¾åƒå¤„ç†ï¼Œç”¨äºæ‹¼æ¥åŠŸèƒ½)
#
# å¯é€‰ä¾èµ–:
# - PIL/Pillow: å¦‚æœä¸å®‰è£…ï¼Œå°†ç¦ç”¨å›¾åƒæ‹¼æ¥åŠŸèƒ½ï¼Œåªä½¿ç”¨æœ€æ–°å›¾åƒ

import asyncio
import time
import logging
from typing import Optional, List, Dict, Any, Callable
from dataclasses import dataclass
from collections import deque
import base64
import io

# OpenAI å…¼å®¹å®¢æˆ·ç«¯
try:
    from openai import AsyncOpenAI
except ImportError:
    AsyncOpenAI = None

# PIL ç”¨äºå›¾åƒå¤„ç†
try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError:
    PIL_AVAILABLE = False


@dataclass
class ContextHistoryItem:
    """ä¸Šä¸‹æ–‡å†å²é¡¹"""
    timestamp: float
    context: str
    trigger_reason: str = "screen_change"


@dataclass 
class AnalysisResult:
    """åˆ†æç»“æœ"""
    new_current_context: str


@dataclass
class CachedImage:
    """ç¼“å­˜çš„å›¾åƒæ•°æ®"""
    timestamp: float
    image_base64: str
    difference_score: float
    metadata: Dict[str, Any]


class ScreenReader:
    """
    å±å¹•å†…å®¹é˜…è¯»å™¨
    
    åŠŸèƒ½ï¼š
    - æ¥æ”¶ screen_analyzer çš„å›¾åƒå˜åŒ–æ¶ˆæ¯
    - ç»´æŠ¤ main_context (æ€»ä½“æ¦‚æ‹¬) å’Œ current_context (è¿‘æœŸå†…å®¹)
    - ä¿å­˜ current_context çš„å†å²è®°å½•
    - ä½¿ç”¨ LLM è§†è§‰æ¨¡å‹ç»“åˆä¸Šä¸‹æ–‡åˆ†ææ–°å›¾åƒ
    - ç¼“å­˜è¢«è·³è¿‡çš„å›¾åƒå˜åŒ–ï¼Œæ‹¼æ¥åä¸€èµ·å¤„ç†
    """
    
    def __init__(
        self,
        api_key: str,
        base_url: str,
        model_name: str = "qwen-vl-plus",
        max_history_size: int = 20,
        timeout_seconds: int = 30,
        max_cached_images: int = 5
    ):
        """
        åˆå§‹åŒ–å±å¹•é˜…è¯»å™¨
        
        Args:
            api_key: OpenAI å…¼å®¹ API Key
            base_url: OpenAI å…¼å®¹ Base URL
            model_name: è§†è§‰æ¨¡å‹åç§°
            max_history_size: æœ€å¤§å†å²è®°å½•æ•°é‡
            timeout_seconds: è¯·æ±‚è¶…æ—¶æ—¶é—´
            max_cached_images: æœ€å¤§ç¼“å­˜å›¾åƒæ•°é‡
        """
        self.api_key = api_key
        self.base_url = base_url
        self.model_name = model_name
        self.max_history_size = max_history_size
        self.timeout_seconds = timeout_seconds
        self.max_cached_images = max_cached_images
        
        # ä¸Šä¸‹æ–‡çŠ¶æ€
        self.main_context = "å±å¹•å†…å®¹å°šæœªåˆå§‹åŒ–"
        self.current_context = "å½“å‰å±å¹•å†…å®¹å°šæœªè·å–"
        
        # å†å²è®°å½•
        self.context_history: deque[ContextHistoryItem] = deque(maxlen=max_history_size)
        
        # å›¾åƒç¼“å­˜
        self._cached_images: deque[CachedImage] = deque(maxlen=max_cached_images)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.total_analyses = 0
        self.main_context_updates = 0
        self.current_context_updates = 0
        self.last_analysis_time = 0.0
        self.cached_images_count = 0
        self.stitched_analyses_count = 0
        
        # æ§åˆ¶å˜é‡
        self.is_initialized = False
        self._analysis_lock = asyncio.Lock()
        self._is_processing = False  # æ ‡è®°æ˜¯å¦æ­£åœ¨å¤„ç†
        self._drop_count = 0  # ä¸¢å¼ƒçš„è¯·æ±‚è®¡æ•°
        
        # å›è°ƒå‡½æ•°
        self.on_context_updated: Optional[Callable] = None
        
        # æ—¥å¿—
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # æ£€æŸ¥ä¾èµ–
        if not PIL_AVAILABLE:
            self.logger.warning("PIL åº“ä¸å¯ç”¨ï¼Œå›¾åƒæ‹¼æ¥åŠŸèƒ½å°†è¢«ç¦ç”¨")
        
        # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
        if AsyncOpenAI is None:
            raise ImportError("ç¼ºå°‘ openai åº“ï¼Œè¯·è¿è¡Œ: pip install openai")
        
        try:
            self.openai_client = AsyncOpenAI(
                api_key=api_key,
                base_url=base_url,
                timeout=timeout_seconds
            )
            self.is_initialized = True
            self.logger.info(f"ScreenReader åˆå§‹åŒ–æˆåŠŸï¼Œæ¨¡å‹: {model_name}")
        except Exception as e:
            self.logger.error(f"åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯å¤±è´¥: {e}")
            raise
    
    def set_context_update_callback(self, callback: Callable[[Dict[str, Any]], None]):
        """è®¾ç½®ä¸Šä¸‹æ–‡æ›´æ–°å›è°ƒå‡½æ•°"""
        self.on_context_updated = callback
    
    async def process_screen_change(self, change_data: Dict[str, Any]) -> Optional[AnalysisResult]:
        """
        å¤„ç†æ¥è‡ª screen_analyzer çš„å±å¹•å˜åŒ–æ¶ˆæ¯
        æ™ºèƒ½å¹¶å‘æ§åˆ¶ï¼šå¦‚æœæ­£åœ¨å¤„ç†ï¼Œç¼“å­˜å›¾åƒè€Œä¸æ˜¯ä¸¢å¼ƒ
        
        Args:
            change_data: åŒ…å«å›¾åƒæ•°æ®å’Œå…ƒä¿¡æ¯çš„å­—å…¸
            
        Returns:
            åˆ†æç»“æœ
        """
        if not self.is_initialized:
            self.logger.warning("ScreenReader æœªæ­£ç¡®åˆå§‹åŒ–")
            return None
        
        # æ£€æŸ¥æ˜¯å¦æ­£åœ¨å¤„ç†
        if self._is_processing:
            # ç¼“å­˜å½“å‰å›¾åƒè€Œä¸æ˜¯ä¸¢å¼ƒ
            cached_image = CachedImage(
                timestamp=change_data.get("timestamp", time.time()),
                image_base64=change_data.get("image_base64", ""),
                difference_score=change_data.get("difference_score", 0.0),
                metadata=change_data
            )
            
            self._cached_images.append(cached_image)
            self.cached_images_count += 1
            
            self.logger.debug(f"LLMæ­£åœ¨å¤„ç†ä¸­ï¼Œç¼“å­˜å›¾åƒ (ç¼“å­˜æ•°é‡: {len(self._cached_images)})")
            return None
        
        # å¼€å§‹å¤„ç†
        return await self._process_image_request(change_data)
    
    async def _process_image_request(self, change_data: Dict[str, Any]) -> Optional[AnalysisResult]:
        """å¤„ç†å›¾åƒè¯·æ±‚ï¼ŒåŒ…æ‹¬ç¼“å­˜çš„å›¾åƒ"""
        try:
            self._is_processing = True
            
            # å‡†å¤‡è¦å¤„ç†çš„å›¾åƒåˆ—è¡¨
            images_to_process = []
            
            # æ·»åŠ ç¼“å­˜çš„å›¾åƒ
            while self._cached_images:
                cached_image = self._cached_images.popleft()
                images_to_process.append(cached_image)
            
            # æ·»åŠ å½“å‰å›¾åƒ
            current_image = CachedImage(
                timestamp=change_data.get("timestamp", time.time()),
                image_base64=change_data.get("image_base64", ""),
                difference_score=change_data.get("difference_score", 0.0),
                metadata=change_data
            )
            images_to_process.append(current_image)
            
            # å¤„ç†å›¾åƒ
            if len(images_to_process) > 1:
                self.logger.info(f"å¤„ç† {len(images_to_process)} å¼ è¿ç»­å›¾åƒå˜åŒ–")
                self.stitched_analyses_count += 1
            
            result = await self._analyze_images(images_to_process)
            
            if result:
                # æ›´æ–°ä¸Šä¸‹æ–‡
                await self._update_contexts(result)
                
                # è§¦å‘å›è°ƒ
                if self.on_context_updated:
                    await self._trigger_callback(result, change_data, len(images_to_process))
            
            return result
            
        finally:
            self._is_processing = False
    
    def _stitch_images(self, images: List[CachedImage]) -> Optional[str]:
        """æ¨ªå‘æ‹¼æ¥å¤šå¼ å›¾åƒ"""
        if not PIL_AVAILABLE:
            self.logger.warning("PIL ä¸å¯ç”¨ï¼Œæ— æ³•æ‹¼æ¥å›¾åƒï¼Œä½¿ç”¨æœ€åä¸€å¼ ")
            return images[-1].image_base64 if images else None
        
        if len(images) == 1:
            return images[0].image_base64
        
        try:
            pil_images = []
            
            # è§£ç æ‰€æœ‰å›¾åƒ
            for cached_img in images:
                img_data = base64.b64decode(cached_img.image_base64)
                pil_img = Image.open(io.BytesIO(img_data))
                pil_images.append(pil_img)
            
            # è®¡ç®—æ‹¼æ¥åçš„å°ºå¯¸
            max_height = max(img.height for img in pil_images)
            total_width = sum(img.width for img in pil_images)
            
            # åˆ›å»ºæ–°çš„å›¾åƒ
            stitched_image = Image.new('RGB', (total_width, max_height), (255, 255, 255))
            
            # é€ä¸ªç²˜è´´å›¾åƒ
            x_offset = 0
            for img in pil_images:
                # å¦‚æœé«˜åº¦ä¸åŒï¼Œå±…ä¸­å¯¹é½
                y_offset = (max_height - img.height) // 2
                stitched_image.paste(img, (x_offset, y_offset))
                x_offset += img.width
            
            # è½¬æ¢å› base64
            buffer = io.BytesIO()
            stitched_image.save(buffer, format='PNG')
            stitched_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            self.logger.debug(f"æˆåŠŸæ‹¼æ¥ {len(images)} å¼ å›¾åƒï¼Œå°ºå¯¸: {total_width}x{max_height}")
            return stitched_base64
            
        except Exception as e:
            self.logger.error(f"æ‹¼æ¥å›¾åƒå¤±è´¥: {e}")
            # æ‹¼æ¥å¤±è´¥ï¼Œè¿”å›æœ€åä¸€å¼ å›¾åƒ
            return images[-1].image_base64 if images else None
    
    async def _analyze_images(self, images: List[CachedImage]) -> Optional[AnalysisResult]:
        """åˆ†æå•å¼ æˆ–å¤šå¼ æ‹¼æ¥çš„å›¾åƒ"""
        try:
            self.logger.info("å¼€å§‹å¤„ç†å±å¹•å˜åŒ–...")
            
            if not images:
                self.logger.error("æ²¡æœ‰å›¾åƒæ•°æ®")
                return None
            
            # æ‹¼æ¥å›¾åƒ
            stitched_image_base64 = self._stitch_images(images)
            if not stitched_image_base64:
                self.logger.error("å›¾åƒæ‹¼æ¥å¤±è´¥")
                return None
            
            # åˆ†æå›¾åƒ
            result = await self._analyze_screen_image(
                image_base64=stitched_image_base64,
                images_count=len(images),
                metadata=images[-1].metadata  # ä½¿ç”¨æœ€æ–°å›¾åƒçš„å…ƒæ•°æ®
            )
            
            return result
            
        except Exception as e:
            self.logger.error(f"å¤„ç†å±å¹•å˜åŒ–å¤±è´¥: {e}", exc_info=True)
            return None
    
    async def _analyze_screen_image(
        self, 
        image_base64: str, 
        images_count: int,
        metadata: Dict[str, Any]
    ) -> Optional[AnalysisResult]:
        """ä½¿ç”¨ LLM è§†è§‰æ¨¡å‹åˆ†æå±å¹•å›¾åƒ"""
        
        # æ„å»ºåˆ†ææç¤ºè¯
        analysis_prompt = self._build_analysis_prompt(images_count)
        
        # æ„å»º OpenAI Vision API æ¶ˆæ¯
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": analysis_prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/png;base64,{image_base64}"
                        }
                    }
                ]
            }
        ]
        
        try:
            self.logger.debug(f"å‘é€å›¾åƒåˆ†æè¯·æ±‚åˆ° {self.base_url} (å›¾åƒæ•°é‡: {images_count})")
            
            completion = await self.openai_client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                max_tokens=1000,
                temperature=0.3  # ä½¿ç”¨è¾ƒä½æ¸©åº¦ä¿è¯ä¸€è‡´æ€§
            )
            
            if completion.choices and completion.choices[0].message:
                response_content = completion.choices[0].message.content
                if response_content:
                    # è§£æ LLM å“åº”
                    result = self._parse_llm_response(response_content, metadata)
                    self.total_analyses += 1
                    self.last_analysis_time = time.time()
                    return result
            
            self.logger.warning("LLM å“åº”å†…å®¹ä¸ºç©º")
            return None
            
        except Exception as e:
            self.logger.error(f"è°ƒç”¨ LLM åˆ†æå›¾åƒå¤±è´¥: {e}", exc_info=True)
            return None
    
    def _build_analysis_prompt(self, images_count: int = 1) -> str:
        """æ„å»ºå›¾åƒåˆ†ææç¤ºè¯"""
        
        if images_count == 1:
            prompt = f"""
è¯·åˆ†æè¿™å¼ å±å¹•æˆªå›¾ï¼Œå¹¶æ ¹æ®ä¸Šä¸€æ—¶åˆ»å±å¹•çš„å†…å®¹ï¼Œæ€»ç»“å˜åŒ–ï¼Œç”Ÿæˆæ–°çš„å±å¹•å†…å®¹æè¿°ã€‚

ä¸Šä¸€æ—¶åˆ»å±å¹•çš„å†…å®¹: {self.current_context}

è¯·æ ¹æ®å›¾åƒå†…å®¹å’Œä¸Šè¿°ä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆæ–°çš„å±å¹•å†…å®¹æè¿°ã€‚

è¯·ç›´æ¥å›å¤å±å¹•å†…å®¹æè¿°ï¼Œä¸éœ€è¦JSONæ ¼å¼ã€‚æè¿°åº”è¯¥ç®€æ´æ˜äº†ï¼Œ1-2å¥è¯å³å¯ã€‚
"""
        else:
            prompt = f"""
è¯·åˆ†æè¿™å¼ æ¨ªå‘æ‹¼æ¥çš„å±å¹•æˆªå›¾ã€‚è¿™å¼ å›¾åƒåŒ…å«äº† {images_count} ä¸ªè¿ç»­çš„å±å¹•å˜åŒ–æ—¶åˆ»ï¼Œä»å·¦åˆ°å³æŒ‰æ—¶é—´é¡ºåºæ’åˆ—ã€‚

ä¸Šä¸€æ—¶åˆ»å±å¹•çš„å†…å®¹: {self.current_context}

è¯·æ ¹æ®è¿™äº›è¿ç»­çš„å±å¹•å˜åŒ–å’Œä¸Šè¿°ä¸Šä¸‹æ–‡ï¼Œæ€»ç»“æ•´ä¸ªå˜åŒ–è¿‡ç¨‹ï¼Œç”Ÿæˆæ–°çš„å±å¹•å†…å®¹æè¿°ã€‚

æ³¨æ„ï¼š
- å›¾åƒä»å·¦åˆ°å³æ˜¾ç¤ºäº†è¿ç»­çš„ {images_count} ä¸ªæ—¶åˆ»
- é‡ç‚¹å…³æ³¨æ•´ä¸ªå˜åŒ–è¿‡ç¨‹å’Œæœ€ç»ˆçŠ¶æ€
- æè¿°åº”è¯¥ä½“ç°å˜åŒ–çš„è¿ç»­æ€§

è¯·ç›´æ¥å›å¤å±å¹•å†…å®¹æè¿°ï¼Œä¸éœ€è¦JSONæ ¼å¼ã€‚æè¿°åº”è¯¥ç®€æ´æ˜äº†ï¼Œ1-2å¥è¯å³å¯ã€‚
"""
        
        return prompt
    
    def _parse_llm_response(self, response: str, metadata: Dict[str, Any]) -> Optional[AnalysisResult]:
        """è§£æ LLM çš„æ–‡æœ¬å“åº”"""
        try:
            # æ¸…ç†å“åº”æ–‡æœ¬
            response = response.strip()
            
            # ç§»é™¤å¯èƒ½çš„ä»£ç å—æ ‡è®°
            if response.startswith("```"):
                lines = response.split('\n')
                if len(lines) > 1:
                    response = '\n'.join(lines[1:])
                if response.endswith("```"):
                    response = response[:-3]
            
            # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
            response = response.strip()
            
            # å¦‚æœå“åº”ä¸ºç©ºï¼Œè¿”å›é»˜è®¤æè¿°
            if not response:
                response = "å±å¹•å†…å®¹å·²æ›´æ–°"
            
            # åˆ›å»ºåˆ†æç»“æœ
            result = AnalysisResult(
                new_current_context=response
            )
            
            self.logger.debug(f"æˆåŠŸè§£æ LLM å“åº”: {response[:50]}...")
            return result
            
        except Exception as e:
            self.logger.error(f"è§£æ LLM å“åº”æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            self.logger.debug(f"åŸå§‹å“åº”: {response[:200]}...")
            
            # è¿”å›å¤‡ç”¨ç»“æœ
            return AnalysisResult(
                new_current_context="å±å¹•å†…å®¹å·²æ›´æ–° (AIåˆ†æå¼‚å¸¸)"
            )
    
    async def _update_contexts(self, result: AnalysisResult):
        """æ›´æ–°ä¸Šä¸‹æ–‡çŠ¶æ€"""
        # ä¿å­˜æ—§çš„ current_context åˆ°å†å²è®°å½•
        if self.current_context != "å½“å‰å±å¹•å†…å®¹å°šæœªè·å–":
            history_item = ContextHistoryItem(
                timestamp=time.time(),
                context=self.current_context,
                trigger_reason="screen_change"
            )
            self.context_history.append(history_item)
        
        # æ›´æ–° current_context
        old_current = self.current_context
        self.current_context = result.new_current_context
        self.current_context_updates += 1
        
        self.logger.info(f"æ›´æ–° current_context: {old_current[:30]}... -> {self.current_context[:30]}...")
    
    async def _trigger_callback(self, result: AnalysisResult, change_data: Dict[str, Any], images_processed: int = 1):
        """è§¦å‘ä¸Šä¸‹æ–‡æ›´æ–°å›è°ƒ"""
        if not self.on_context_updated:
            return
        
        callback_data = {
            "main_context": self.main_context,
            "current_context": self.current_context,
            "analysis_result": result,
            "change_data": change_data,
            "images_processed": images_processed,
            "statistics": self.get_statistics()
        }
        
        try:
            if asyncio.iscoroutinefunction(self.on_context_updated):
                await self.on_context_updated(callback_data)
            else:
                self.on_context_updated(callback_data)
        except Exception as e:
            self.logger.error(f"æ‰§è¡Œä¸Šä¸‹æ–‡æ›´æ–°å›è°ƒå¤±è´¥: {e}", exc_info=True)
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_analyses": self.total_analyses,
            "main_context_updates": self.main_context_updates,
            "current_context_updates": self.current_context_updates,
            "history_size": len(self.context_history),
            "last_analysis_time": self.last_analysis_time,
            "current_main_context": self.main_context,
            "current_context": self.current_context,
            "dropped_requests": self._drop_count,
            "cached_images_count": self.cached_images_count,
            "stitched_analyses_count": self.stitched_analyses_count,
            "current_cache_size": len(self._cached_images),
            "is_processing": self._is_processing,
            "pil_available": PIL_AVAILABLE
        }
    
    def get_context_history(self, limit: Optional[int] = None) -> List[Dict[str, Any]]:
        """è·å–ä¸Šä¸‹æ–‡å†å²è®°å½•"""
        history = list(self.context_history)
        if limit:
            history = history[-limit:]
        
        return [
            {
                "timestamp": item.timestamp,
                "context": item.context,
                "trigger_reason": item.trigger_reason
            }
            for item in history
        ]
    
    def update_main_context_manually(self, new_main_context: str):
        """æ‰‹åŠ¨æ›´æ–°ä¸»ä¸Šä¸‹æ–‡"""
        old_main = self.main_context
        self.main_context = new_main_context
        self.main_context_updates += 1
        
        # æ·»åŠ åˆ°å†å²è®°å½•
        history_item = ContextHistoryItem(
            timestamp=time.time(),
            context=f"ä¸»ä¸Šä¸‹æ–‡æ‰‹åŠ¨æ›´æ–°: {new_main_context}",
            trigger_reason="manual_update"
        )
        self.context_history.append(history_item)
        
        self.logger.info(f"æ‰‹åŠ¨æ›´æ–° main_context: {old_main[:30]}... -> {new_main_context[:30]}...")
    
    def clear_history(self):
        """æ¸…ç©ºå†å²è®°å½•"""
        self.context_history.clear()
        self.logger.info("ä¸Šä¸‹æ–‡å†å²è®°å½•å·²æ¸…ç©º")
    
    def clear_cached_images(self):
        """æ¸…ç©ºå›¾åƒç¼“å­˜"""
        cleared_count = len(self._cached_images)
        self._cached_images.clear()
        self.logger.info(f"å·²æ¸…ç©º {cleared_count} å¼ ç¼“å­˜å›¾åƒ")
    
    def reset_contexts(self):
        """é‡ç½®æ‰€æœ‰ä¸Šä¸‹æ–‡"""
        self.main_context = "å±å¹•å†…å®¹å°šæœªåˆå§‹åŒ–"
        self.current_context = "å½“å‰å±å¹•å†…å®¹å°šæœªè·å–"
        self.clear_history()
        self.clear_cached_images()
        self.total_analyses = 0
        self.main_context_updates = 0
        self.current_context_updates = 0
        self.cached_images_count = 0
        self.stitched_analyses_count = 0
        self.logger.info("æ‰€æœ‰ä¸Šä¸‹æ–‡å·²é‡ç½®")


# ä½¿ç”¨ç¤ºä¾‹ - æ•´ä½“ååŒè¿ä½œ
async def example_usage():
    """å®Œæ•´çš„å±å¹•ç›‘æ§ç¤ºä¾‹ï¼šscreen_analyzer + screen_reader ååŒå·¥ä½œ"""
    
    # å¯¼å…¥ ScreenAnalyzer
    try:
        from .screen_analyzer import ScreenAnalyzer
    except ImportError:
        # å¦‚æœåœ¨å½“å‰ç›®å½•è¿è¡Œï¼Œå°è¯•ç›´æ¥å¯¼å…¥
        try:
            from screen_analyzer import ScreenAnalyzer
        except ImportError:
            print("é”™è¯¯: æ— æ³•å¯¼å…¥ ScreenAnalyzerï¼Œè¯·ç¡®ä¿ screen_analyzer.py åœ¨åŒä¸€ç›®å½•")
            return
    
    print("ğŸš€ å¯åŠ¨å®Œæ•´çš„å±å¹•ç›‘æ§ç³»ç»Ÿ...")
    
    # 1. åˆ›å»ºå±å¹•é˜…è¯»å™¨
    reader = ScreenReader(
        api_key="sk-587745e2aa7843d8b9217655a7c4d17c",
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        model_name="qwen2.5-vl-72b-instruct"
    )
    
    # 2. åˆ›å»ºå±å¹•åˆ†æå™¨
    analyzer = ScreenAnalyzer(
        interval=0.3,           # 1ç§’æˆªå›¾é—´éš”ï¼ˆæµ‹è¯•ç”¨ï¼‰
        diff_threshold=25.0,    # è¾ƒä½çš„é˜ˆå€¼ï¼Œæ›´å®¹æ˜“è§¦å‘
        check_window=3,         # æ£€æŸ¥æœ€è¿‘2å¸§
        max_cache_size=5
    )
    
    # 3. è®¾ç½®ä¸Šä¸‹æ–‡æ›´æ–°å›è°ƒ
    async def on_context_update(data):
        print("\nğŸ“„ ä¸Šä¸‹æ–‡å·²æ›´æ–°:")
        print(f"  ğŸ¯ ä¸»ä¸Šä¸‹æ–‡: {data['main_context']}")
        print(f"  ğŸ“ å½“å‰ä¸Šä¸‹æ–‡: {data['current_context']}")
        print(f"  ğŸ†• æ–°å†…å®¹: {data['analysis_result'].new_current_context}")
        print(f"  ğŸ–¼ï¸ å¤„ç†å›¾åƒæ•°: {data['images_processed']}")
        stats = data['statistics']
        print(f"  ğŸ“Š æ›´æ–°æ¬¡æ•°: {stats['current_context_updates']}")
        print(f"  ğŸ—‘ï¸ ä¸¢å¼ƒè¯·æ±‚: {stats['dropped_requests']}, æ­£åœ¨å¤„ç†: {'ğŸŸ¢' if stats['is_processing'] else 'ğŸ”´'}")
        print(f"  ğŸ“¦ ç¼“å­˜å›¾åƒ: {stats['current_cache_size']}/{stats['cached_images_count']}, æ‹¼æ¥åˆ†æ: {stats['stitched_analyses_count']}")
        print(f"  ğŸ¨ PILå¯ç”¨: {'âœ…' if stats['pil_available'] else 'âŒ'}")
        print("-" * 60)
    
    reader.set_context_update_callback(on_context_update)
    
    # 4. è®¾ç½®å˜åŒ–æ£€æµ‹å›è°ƒ - è¿æ¥ analyzer åˆ° reader
    async def on_screen_change(change_data):
        print("\nğŸ” æ£€æµ‹åˆ°å±å¹•å˜åŒ–!")
        print(f"  â° æ—¶é—´æˆ³: {change_data['timestamp']}")
        print(f"  ğŸ“Š å·®å¼‚åˆ†æ•°: {change_data['difference_score']:.2f}")
        print(f"  ğŸ–¼ï¸ å›¾åƒå¤§å°: {len(change_data['image_base64'])} bytes")
        
        # å°†å˜åŒ–æ•°æ®ä¼ é€’ç»™ screen_reader è¿›è¡Œåˆ†æ
        try:
            result = await reader.process_screen_change(change_data)
            if result:
                print(f"  âœ… AIåˆ†æå®Œæˆ: {result.new_current_context}")
            else:
                print("  ğŸ“¦ å›¾åƒå·²ç¼“å­˜æˆ–åˆ†æå¤±è´¥")
        except Exception as e:
            print(f"  âš ï¸ å¤„ç†å˜åŒ–æ—¶å‡ºé”™: {e}")
    
    analyzer.set_change_callback(on_screen_change)
    
    # 5. å¯åŠ¨ç³»ç»Ÿ
    print(f"ğŸ“± å¯åŠ¨å±å¹•åˆ†æå™¨ (é—´éš”: {analyzer.interval}s, é˜ˆå€¼: {analyzer.diff_threshold})")
    
    try:
        # å¯åŠ¨åˆ†æå™¨
        await analyzer.start()
        
        print("ğŸ® ç³»ç»Ÿè¿è¡Œä¸­... (æŒ‰ Ctrl+C åœæ­¢)")
        print("ğŸ’¡ æç¤º: åœ¨å±å¹•ä¸Šç§»åŠ¨é¼ æ ‡æˆ–åˆ‡æ¢çª—å£æ¥è§¦å‘å˜åŒ–æ£€æµ‹")
        print("ğŸ–¼ï¸ æ–°åŠŸèƒ½: è¢«è·³è¿‡çš„å›¾åƒä¼šè¢«ç¼“å­˜å¹¶æ‹¼æ¥å¤„ç†ï¼Œé¿å…ä¸¢å¤±å˜åŒ–ä¿¡æ¯")
        print("=" * 60)
        
        # è¿è¡ŒæŒ‡å®šæ—¶é—´
        runtime = 60  # è¿è¡Œ30ç§’
        print(f"â³ å°†è¿è¡Œ {runtime} ç§’è¿›è¡Œæµ‹è¯•...")
        
        await asyncio.sleep(runtime)
        
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­...")
    
    finally:
        # åœæ­¢åˆ†æå™¨
        print("ğŸ›‘ æ­£åœ¨åœæ­¢å±å¹•åˆ†æå™¨...")
        await analyzer.stop()
        
        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
        print("\nğŸ“ˆ æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯:")
        stats = reader.get_statistics()
        analyzer_stats = analyzer.get_cache_status()
        
        print(f"  ğŸ”¬ æ€»åˆ†ææ¬¡æ•°: {stats['total_analyses']}")
        print(f"  ğŸ“ current_contextæ›´æ–°: {stats['current_context_updates']}")
        print(f"  ğŸ¯ main_contextæ›´æ–°: {stats['main_context_updates']}")
        print(f"  ğŸ—‘ï¸ ä¸¢å¼ƒçš„è¯·æ±‚: {stats['dropped_requests']}")
        print(f"  ğŸ“¦ ç¼“å­˜çš„å›¾åƒæ€»æ•°: {stats['cached_images_count']}")
        print(f"  ğŸ¬ æ‹¼æ¥åˆ†ææ¬¡æ•°: {stats['stitched_analyses_count']}")
        print(f"  ğŸ¨ PILåº“çŠ¶æ€: {'å¯ç”¨' if stats['pil_available'] else 'ä¸å¯ç”¨'}")
        print(f"  ğŸ“± åˆ†æå™¨ç¼“å­˜: {analyzer_stats['cache_size']}")
        print(f"  ğŸ›ï¸ å½“å‰main_context: {stats['current_main_context']}")
        print(f"  ğŸ“„ å½“å‰context: {stats['current_context']}")
        
        print("\nâœ… æµ‹è¯•å®Œæˆ!")


if __name__ == "__main__":
    asyncio.run(example_usage())
